[2025-02-18T13:34:24.811-0600] {processor.py:186} INFO - Started process (PID=83877) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:34:24.815-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T13:34:24.861-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:34:24.852-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:34:24.907-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:34:24.959-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.232 seconds
[2025-02-18T13:34:55.498-0600] {processor.py:186} INFO - Started process (PID=84246) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:34:55.502-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T13:34:55.509-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:34:55.508-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:34:55.515-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:34:55.533-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.046 seconds
[2025-02-18T13:35:26.153-0600] {processor.py:186} INFO - Started process (PID=84576) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:35:26.156-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T13:35:26.161-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:35:26.161-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:35:26.165-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:35:26.189-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.048 seconds
[2025-02-18T13:35:27.313-0600] {processor.py:186} INFO - Started process (PID=84620) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:35:27.316-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T13:35:27.322-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:35:27.320-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:35:27.337-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:35:27.327-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 879, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1017, in get_code
  File "<frozen importlib._bootstrap_external>", line 947, in source_to_code
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dags.py", line 3
    from airflow.decorators import
                                  ^
SyntaxError: invalid syntax
[2025-02-18T13:35:27.338-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:35:27.435-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.135 seconds
[2025-02-18T13:35:29.552-0600] {processor.py:186} INFO - Started process (PID=84656) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:35:29.556-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T13:35:29.562-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:35:29.561-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:35:29.572-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:35:29.568-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 879, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1017, in get_code
  File "<frozen importlib._bootstrap_external>", line 947, in source_to_code
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dags.py", line 3
    from airflow.decorators import 
                                   ^
SyntaxError: invalid syntax
[2025-02-18T13:35:29.573-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:35:29.625-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.096 seconds
[2025-02-18T13:35:33.202-0600] {processor.py:186} INFO - Started process (PID=84701) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:35:33.204-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T13:35:33.210-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:35:33.209-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:35:33.213-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:35:33.239-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.051 seconds
[2025-02-18T13:36:03.729-0600] {processor.py:186} INFO - Started process (PID=84984) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:36:03.730-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T13:36:03.734-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:36:03.733-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:36:03.741-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:36:03.771-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.056 seconds
[2025-02-18T13:36:05.996-0600] {processor.py:186} INFO - Started process (PID=85023) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:36:05.998-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T13:36:06.001-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:36:06.001-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:36:06.008-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:36:06.005-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 879, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1017, in get_code
  File "<frozen importlib._bootstrap_external>", line 947, in source_to_code
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dags.py", line 5
    @task(task_id="")
SyntaxError: invalid syntax
[2025-02-18T13:36:06.009-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:36:06.053-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.069 seconds
[2025-02-18T13:36:12.099-0600] {processor.py:186} INFO - Started process (PID=85078) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:36:12.100-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T13:36:12.104-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:36:12.103-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:36:12.111-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:36:12.109-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 879, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1017, in get_code
  File "<frozen importlib._bootstrap_external>", line 947, in source_to_code
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dags.py", line 5
    @task(task_id="First tasl")
SyntaxError: invalid syntax
[2025-02-18T13:36:12.112-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:36:12.154-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.064 seconds
[2025-02-18T13:36:13.261-0600] {processor.py:186} INFO - Started process (PID=85083) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:36:13.262-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T13:36:13.268-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:36:13.267-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:36:13.273-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:36:13.272-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 879, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1017, in get_code
  File "<frozen importlib._bootstrap_external>", line 947, in source_to_code
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dags.py", line 5
    @task(task_id="First task")
SyntaxError: invalid syntax
[2025-02-18T13:36:13.274-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:36:13.315-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.065 seconds
[2025-02-18T13:36:43.643-0600] {processor.py:186} INFO - Started process (PID=85480) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:36:43.646-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T13:36:43.651-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:36:43.650-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:36:43.659-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:36:43.657-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 879, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1017, in get_code
  File "<frozen importlib._bootstrap_external>", line 947, in source_to_code
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dags.py", line 5
    @task(task_id="First task")
SyntaxError: invalid syntax
[2025-02-18T13:36:43.660-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:36:43.700-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.068 seconds
[2025-02-18T13:36:50.638-0600] {processor.py:186} INFO - Started process (PID=85538) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:36:50.639-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T13:36:50.644-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:36:50.643-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:36:50.652-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:36:50.684-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.059 seconds
[2025-02-18T13:37:53.728-0600] {processor.py:186} INFO - Started process (PID=86166) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:37:53.731-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T13:37:53.736-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:37:53.735-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:37:53.743-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:37:53.766-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.051 seconds
[2025-02-18T13:38:23.969-0600] {processor.py:186} INFO - Started process (PID=86615) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:38:23.974-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T13:38:23.985-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:38:23.983-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:38:24.007-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:38:24.081-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.159 seconds
[2025-02-18T13:38:54.633-0600] {processor.py:186} INFO - Started process (PID=86995) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:38:54.636-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T13:38:54.641-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:38:54.640-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:38:54.648-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:38:54.669-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.046 seconds
[2025-02-18T13:39:25.174-0600] {processor.py:186} INFO - Started process (PID=87390) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:39:25.178-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T13:39:25.184-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:39:25.182-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:39:25.197-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:39:25.225-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.064 seconds
[2025-02-18T13:39:55.371-0600] {processor.py:186} INFO - Started process (PID=87779) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:39:55.373-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T13:39:55.378-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:39:55.377-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:39:55.384-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:39:55.565-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.232 seconds
[2025-02-18T13:40:26.238-0600] {processor.py:186} INFO - Started process (PID=88120) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:40:26.242-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T13:40:26.246-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:40:26.245-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:40:26.251-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:40:26.499-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.273 seconds
[2025-02-18T13:40:56.748-0600] {processor.py:186} INFO - Started process (PID=88472) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:40:56.751-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T13:40:56.758-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:40:56.757-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:40:56.788-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:40:56.782-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 879, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1017, in get_code
  File "<frozen importlib._bootstrap_external>", line 947, in source_to_code
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dags.py", line 11
    )
     ^
SyntaxError: expected ':'
[2025-02-18T13:40:56.792-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:40:57.006-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.294 seconds
[2025-02-18T13:41:02.148-0600] {processor.py:186} INFO - Started process (PID=88548) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:41:02.157-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T13:41:02.162-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:41:02.161-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:41:02.174-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:41:02.171-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 879, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1017, in get_code
  File "<frozen importlib._bootstrap_external>", line 947, in source_to_code
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dags.py", line 11
    )
     ^
SyntaxError: expected ':'
[2025-02-18T13:41:02.176-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:41:02.248-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.116 seconds
[2025-02-18T13:41:07.428-0600] {processor.py:186} INFO - Started process (PID=88600) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:41:07.430-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T13:41:07.434-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:41:07.433-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:41:07.442-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:41:07.439-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 879, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1017, in get_code
  File "<frozen importlib._bootstrap_external>", line 947, in source_to_code
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dags.py", line 12
    )
     ^
SyntaxError: expected ':'
[2025-02-18T13:41:07.443-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:41:07.491-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.076 seconds
[2025-02-18T13:41:31.103-0600] {processor.py:186} INFO - Started process (PID=88827) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:41:31.107-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T13:41:31.111-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:41:31.110-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:41:32.023-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:41:32.021-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 879, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1017, in get_code
  File "<frozen importlib._bootstrap_external>", line 947, in source_to_code
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dags.py", line 12
    )
     ^
SyntaxError: expected ':'
[2025-02-18T13:41:32.024-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:41:32.078-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.984 seconds
[2025-02-18T13:41:46.010-0600] {processor.py:186} INFO - Started process (PID=88975) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:41:46.011-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T13:41:46.017-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:41:46.015-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:41:46.027-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:41:46.025-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 879, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1017, in get_code
  File "<frozen importlib._bootstrap_external>", line 947, in source_to_code
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dags.py", line 12
    )
     ^
SyntaxError: expected ':'
[2025-02-18T13:41:46.028-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:41:46.151-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.161 seconds
[2025-02-18T13:41:50.420-0600] {processor.py:186} INFO - Started process (PID=89023) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:41:50.421-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T13:41:50.425-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:41:50.424-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:41:50.430-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:41:50.429-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 879, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1017, in get_code
  File "<frozen importlib._bootstrap_external>", line 947, in source_to_code
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dags.py", line 12
    )
     ^
SyntaxError: expected ':'
[2025-02-18T13:41:50.431-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:41:50.468-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.061 seconds
[2025-02-18T13:41:52.693-0600] {processor.py:186} INFO - Started process (PID=89039) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:41:52.695-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T13:41:52.700-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:41:52.699-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:41:52.708-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:41:52.706-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 879, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1017, in get_code
  File "<frozen importlib._bootstrap_external>", line 947, in source_to_code
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dags.py", line 12
    )
     ^
SyntaxError: expected ':'
[2025-02-18T13:41:52.711-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:41:52.765-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.086 seconds
[2025-02-18T13:41:53.648-0600] {processor.py:186} INFO - Started process (PID=89043) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:41:53.649-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T13:41:53.652-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:41:53.651-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:41:53.659-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:41:53.657-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 879, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1017, in get_code
  File "<frozen importlib._bootstrap_external>", line 947, in source_to_code
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dags.py", line 12
    )
     ^
SyntaxError: expected ':'
[2025-02-18T13:41:53.660-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:41:53.700-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.060 seconds
[2025-02-18T13:42:23.804-0600] {processor.py:186} INFO - Started process (PID=89410) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:42:23.808-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T13:42:23.814-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:42:23.813-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:42:23.832-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:42:23.820-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 879, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1017, in get_code
  File "<frozen importlib._bootstrap_external>", line 947, in source_to_code
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dags.py", line 12
    )
     ^
SyntaxError: expected ':'
[2025-02-18T13:42:23.835-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:42:24.170-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.379 seconds
[2025-02-18T13:42:26.252-0600] {processor.py:186} INFO - Started process (PID=89477) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:42:26.253-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T13:42:26.258-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:42:26.257-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:42:26.306-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:42:26.297-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 879, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1017, in get_code
  File "<frozen importlib._bootstrap_external>", line 947, in source_to_code
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dags.py", line 13
    )
     ^
SyntaxError: expected ':'
[2025-02-18T13:42:26.307-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:42:26.399-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.160 seconds
[2025-02-18T13:42:57.521-0600] {processor.py:186} INFO - Started process (PID=89700) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:42:57.524-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T13:42:57.529-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:42:57.528-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:42:57.536-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:42:57.534-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 879, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1017, in get_code
  File "<frozen importlib._bootstrap_external>", line 947, in source_to_code
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dags.py", line 13
    )
     ^
SyntaxError: expected ':'
[2025-02-18T13:42:57.537-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:42:57.571-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.088 seconds
[2025-02-18T13:43:28.715-0600] {processor.py:186} INFO - Started process (PID=89924) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:43:28.719-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T13:43:28.722-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:43:28.722-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:43:28.728-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:43:28.726-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 879, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1017, in get_code
  File "<frozen importlib._bootstrap_external>", line 947, in source_to_code
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dags.py", line 13
    )
     ^
SyntaxError: expected ':'
[2025-02-18T13:43:28.728-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:43:28.758-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.054 seconds
[2025-02-18T13:43:58.902-0600] {processor.py:186} INFO - Started process (PID=90151) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:43:58.904-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T13:43:58.910-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:43:58.909-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:43:58.918-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:43:58.916-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 879, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1017, in get_code
  File "<frozen importlib._bootstrap_external>", line 947, in source_to_code
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dags.py", line 13
    )
     ^
SyntaxError: expected ':'
[2025-02-18T13:43:58.918-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:43:59.038-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.148 seconds
[2025-02-18T13:44:05.737-0600] {processor.py:186} INFO - Started process (PID=90232) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:44:05.739-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T13:44:05.743-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:44:05.742-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:44:05.748-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:44:05.747-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 879, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1017, in get_code
  File "<frozen importlib._bootstrap_external>", line 947, in source_to_code
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dags.py", line 13
    )
     ^
SyntaxError: expected ':'
[2025-02-18T13:44:05.749-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:44:05.807-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.079 seconds
[2025-02-18T13:44:36.050-0600] {processor.py:186} INFO - Started process (PID=90512) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:44:36.053-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T13:44:36.058-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:44:36.057-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:44:36.064-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:44:36.062-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 879, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1017, in get_code
  File "<frozen importlib._bootstrap_external>", line 947, in source_to_code
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dags.py", line 13
    )
     ^
SyntaxError: expected ':'
[2025-02-18T13:44:36.064-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:44:36.103-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.063 seconds
[2025-02-18T13:45:06.365-0600] {processor.py:186} INFO - Started process (PID=90880) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:45:06.369-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T13:45:06.376-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:45:06.375-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:45:06.390-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:45:06.387-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 879, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1017, in get_code
  File "<frozen importlib._bootstrap_external>", line 947, in source_to_code
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dags.py", line 13
    )
     ^
SyntaxError: expected ':'
[2025-02-18T13:45:06.391-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:45:06.452-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.106 seconds
[2025-02-18T13:45:35.515-0600] {processor.py:186} INFO - Started process (PID=91202) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:45:35.518-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T13:45:35.524-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:45:35.523-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:45:35.532-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:45:35.530-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 879, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1017, in get_code
  File "<frozen importlib._bootstrap_external>", line 947, in source_to_code
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dags.py", line 14
    
    ^
IndentationError: expected an indented block after 'with' statement on line 9
[2025-02-18T13:45:35.532-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:45:35.574-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.073 seconds
[2025-02-18T13:45:53.776-0600] {processor.py:186} INFO - Started process (PID=91399) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:45:53.780-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T13:45:53.785-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:45:53.784-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:45:53.799-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:45:53.790-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dags.py", line 9, in <module>
    with DAG(
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dag.py", line 593, in __init__
    validate_key(dag_id)
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/utils/helpers.py", line 57, in validate_key
    raise AirflowException(
airflow.exceptions.AirflowException: The key 'First DAG' has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2025-02-18T13:45:53.800-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:45:53.841-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.076 seconds
[2025-02-18T13:46:24.670-0600] {processor.py:186} INFO - Started process (PID=91832) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:46:24.673-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T13:46:24.678-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:46:24.677-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:46:24.687-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:46:24.684-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dags.py", line 9, in <module>
    with DAG(
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dag.py", line 593, in __init__
    validate_key(dag_id)
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/utils/helpers.py", line 57, in validate_key
    raise AirflowException(
airflow.exceptions.AirflowException: The key 'First DAG' has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2025-02-18T13:46:24.688-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:46:24.726-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.071 seconds
[2025-02-18T13:46:54.937-0600] {processor.py:186} INFO - Started process (PID=92260) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:46:54.939-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T13:46:54.945-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:46:54.944-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:46:54.955-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:46:54.952-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dags.py", line 9, in <module>
    with DAG(
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dag.py", line 593, in __init__
    validate_key(dag_id)
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/utils/helpers.py", line 57, in validate_key
    raise AirflowException(
airflow.exceptions.AirflowException: The key 'First DAG' has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2025-02-18T13:46:54.956-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:46:55.002-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.078 seconds
[2025-02-18T13:47:06.339-0600] {processor.py:186} INFO - Started process (PID=92371) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:47:06.342-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T13:47:06.346-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:47:06.345-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:47:06.370-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:47:06.361-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dags.py", line 14, in <module>
    weatherTask = WeatherAPI()
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/decorators/base.py", line 373, in __call__
    op = self.operator_class(
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/decorators/python.py", line 52, in __init__
    super().__init__(
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/decorators/base.py", line 258, in __init__
    super().__init__(task_id=task_id, **kwargs_to_upstream, **kwargs)
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 976, in __init__
    validate_key(self.task_id)
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/utils/helpers.py", line 57, in validate_key
    raise AirflowException(
airflow.exceptions.AirflowException: The key 'First task' has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2025-02-18T13:47:06.371-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:47:06.409-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.080 seconds
[2025-02-18T13:47:11.437-0600] {processor.py:186} INFO - Started process (PID=92422) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:47:11.440-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T13:47:11.444-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:47:11.443-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:47:11.460-0600] {processor.py:925} INFO - DAG(s) 'FirstDAG' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:47:11.798-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:47:11.797-0600] {override.py:1930} INFO - Created Permission View: can read on DAG:FirstDAG
[2025-02-18T13:47:11.819-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:47:11.818-0600] {override.py:1930} INFO - Created Permission View: can edit on DAG:FirstDAG
[2025-02-18T13:47:11.836-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:47:11.835-0600] {override.py:1930} INFO - Created Permission View: can delete on DAG:FirstDAG
[2025-02-18T13:47:11.863-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:47:11.862-0600] {override.py:1930} INFO - Created Permission View: menu access on DAG Run:FirstDAG
[2025-02-18T13:47:11.881-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:47:11.880-0600] {override.py:1930} INFO - Created Permission View: can read on DAG Run:FirstDAG
[2025-02-18T13:47:11.900-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:47:11.899-0600] {override.py:1930} INFO - Created Permission View: can create on DAG Run:FirstDAG
[2025-02-18T13:47:11.917-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:47:11.917-0600] {override.py:1930} INFO - Created Permission View: can delete on DAG Run:FirstDAG
[2025-02-18T13:47:11.918-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:47:11.918-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-18T13:47:11.936-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:47:11.935-0600] {dag.py:3262} INFO - Creating ORM DAG for FirstDAG
[2025-02-18T13:47:11.952-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:47:11.952-0600] {dag.py:4180} INFO - Setting next_dagrun for FirstDAG to 2025-02-18 00:00:00+00:00, run_after=2025-02-18 00:05:00+00:00
[2025-02-18T13:47:11.989-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.561 seconds
[2025-02-18T13:47:44.301-0600] {processor.py:186} INFO - Started process (PID=93001) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:47:44.303-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T13:47:44.306-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:47:44.305-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:47:44.320-0600] {processor.py:925} INFO - DAG(s) 'FirstDAG' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:47:44.351-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:47:44.350-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-18T13:47:44.522-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:47:44.522-0600] {dag.py:4180} INFO - Setting next_dagrun for FirstDAG to 2025-02-18 00:20:00+00:00, run_after=2025-02-18 00:25:00+00:00
[2025-02-18T13:47:44.554-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.263 seconds
[2025-02-18T13:47:55.720-0600] {processor.py:186} INFO - Started process (PID=93247) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:47:55.722-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T13:47:55.726-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:47:55.725-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:47:55.799-0600] {processor.py:925} INFO - DAG(s) 'FirstDAG' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:47:56.126-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:47:56.126-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-18T13:47:56.156-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:47:56.155-0600] {dag.py:4180} INFO - Setting next_dagrun for FirstDAG to 2025-02-18 00:35:00+00:00, run_after=2025-02-18 00:40:00+00:00
[2025-02-18T13:47:56.199-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.487 seconds
[2025-02-18T13:48:27.004-0600] {processor.py:186} INFO - Started process (PID=93978) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:48:27.007-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T13:48:27.011-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:48:27.010-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:48:27.025-0600] {processor.py:925} INFO - DAG(s) 'FirstDAG' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:48:27.056-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:48:27.055-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-18T13:48:27.233-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:48:27.233-0600] {dag.py:4180} INFO - Setting next_dagrun for FirstDAG to 2025-02-18 01:10:00+00:00, run_after=2025-02-18 01:15:00+00:00
[2025-02-18T13:48:27.268-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.273 seconds
[2025-02-18T13:48:59.324-0600] {processor.py:186} INFO - Started process (PID=94619) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:48:59.326-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T13:48:59.330-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:48:59.329-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:48:59.349-0600] {processor.py:925} INFO - DAG(s) 'FirstDAG' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:48:59.389-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:48:59.388-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-18T13:48:59.574-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:48:59.573-0600] {dag.py:4180} INFO - Setting next_dagrun for FirstDAG to 2025-02-18 01:35:00+00:00, run_after=2025-02-18 01:40:00+00:00
[2025-02-18T13:48:59.609-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.296 seconds
[2025-02-18T13:49:29.002-0600] {processor.py:186} INFO - Started process (PID=95211) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:49:29.006-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T13:49:29.011-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:49:29.010-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:49:29.031-0600] {processor.py:925} INFO - DAG(s) 'FirstDAG' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:49:29.418-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:49:29.417-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-18T13:49:29.460-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:49:29.459-0600] {dag.py:4180} INFO - Setting next_dagrun for FirstDAG to 2025-02-18 00:59:00+00:00, run_after=2025-02-18 05:00:00+00:00
[2025-02-18T13:49:29.501-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.509 seconds
[2025-02-18T13:49:31.920-0600] {processor.py:186} INFO - Started process (PID=95254) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:49:31.922-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T13:49:31.935-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:49:31.934-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:49:31.994-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:49:31.970-0600] {dagbag.py:484} ERROR - Failed to bag_dag: /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/croniter/croniter.py", line 281, in _alphaconv
    return cls.ALPHACONV[index][key]
KeyError: '*1'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/timetables/_cron.py", line 102, in validate
    croniter(self._expression)
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/croniter/croniter.py", line 268, in __init__
    self.expanded, self.nth_weekday_of_month = self.expand(
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/croniter/croniter.py", line 1113, in expand
    return cls._expand(
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/croniter/croniter.py", line 1017, in _expand
    t = cls._alphaconv(field_index, t, expressions)
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/croniter/croniter.py", line 283, in _alphaconv
    raise CroniterNotAlphaError("[{0}] is not acceptable".format(" ".join(expressions)))
croniter.croniter.CroniterNotAlphaError: [* *1 * * *] is not acceptable

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 479, in _process_modules
    dag.validate()
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dag.py", line 845, in validate
    self.timetable.validate()
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/timetables/_cron.py", line 104, in validate
    raise AirflowTimetableInvalid(str(e))
airflow.exceptions.AirflowTimetableInvalid: [* *1 * * *] is not acceptable
[2025-02-18T13:49:31.995-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:49:32.057-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.169 seconds
[2025-02-18T13:49:35.302-0600] {processor.py:186} INFO - Started process (PID=95333) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:49:35.304-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T13:49:35.308-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:49:35.307-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:49:35.326-0600] {processor.py:925} INFO - DAG(s) 'FirstDAG' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:49:35.340-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:49:35.340-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-18T13:49:35.381-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:49:35.380-0600] {dag.py:4180} INFO - Setting next_dagrun for FirstDAG to 2025-02-18 01:55:00+00:00, run_after=2025-02-18 01:56:00+00:00
[2025-02-18T13:49:35.572-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.281 seconds
[2025-02-18T13:50:07.936-0600] {processor.py:186} INFO - Started process (PID=95817) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:50:07.938-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T13:50:07.941-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:50:07.941-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:50:07.957-0600] {processor.py:925} INFO - DAG(s) 'FirstDAG' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:50:08.286-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:50:08.285-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-18T13:50:08.317-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:50:08.316-0600] {dag.py:4180} INFO - Setting next_dagrun for FirstDAG to 2025-02-18 05:02:00+00:00, run_after=2025-02-18 05:03:00+00:00
[2025-02-18T13:50:08.357-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.432 seconds
[2025-02-18T13:50:40.610-0600] {processor.py:186} INFO - Started process (PID=96443) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:50:40.611-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T13:50:40.615-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:50:40.615-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:50:40.632-0600] {processor.py:925} INFO - DAG(s) 'FirstDAG' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:50:40.668-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:50:40.667-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-18T13:50:40.836-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:50:40.836-0600] {dag.py:4180} INFO - Setting next_dagrun for FirstDAG to 2025-02-18 05:10:00+00:00, run_after=2025-02-18 05:11:00+00:00
[2025-02-18T13:50:40.871-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.270 seconds
[2025-02-18T13:51:14.263-0600] {processor.py:186} INFO - Started process (PID=97219) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:51:14.267-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T13:51:14.270-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:51:14.270-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:51:14.288-0600] {processor.py:925} INFO - DAG(s) 'FirstDAG' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:51:14.322-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:51:14.322-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-18T13:51:14.488-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:51:14.488-0600] {dag.py:4180} INFO - Setting next_dagrun for FirstDAG to 2025-02-18 05:18:00+00:00, run_after=2025-02-18 05:19:00+00:00
[2025-02-18T13:51:14.522-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.268 seconds
[2025-02-18T13:51:47.029-0600] {processor.py:186} INFO - Started process (PID=97852) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:51:47.030-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T13:51:47.033-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:51:47.032-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:51:47.048-0600] {processor.py:925} INFO - DAG(s) 'FirstDAG' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:51:47.216-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:51:47.215-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-18T13:51:47.245-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:51:47.244-0600] {dag.py:4180} INFO - Setting next_dagrun for FirstDAG to 2025-02-18 05:26:00+00:00, run_after=2025-02-18 05:27:00+00:00
[2025-02-18T13:51:47.279-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.260 seconds
[2025-02-18T13:52:20.581-0600] {processor.py:186} INFO - Started process (PID=98623) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:52:20.583-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T13:52:20.587-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:52:20.586-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:52:20.623-0600] {processor.py:925} INFO - DAG(s) 'FirstDAG' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:52:20.799-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:52:20.798-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-18T13:52:20.830-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:52:20.830-0600] {dag.py:4180} INFO - Setting next_dagrun for FirstDAG to 2025-02-18 05:34:00+00:00, run_after=2025-02-18 05:35:00+00:00
[2025-02-18T13:52:20.867-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.296 seconds
[2025-02-18T13:52:51.824-0600] {processor.py:186} INFO - Started process (PID=99117) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:52:51.826-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T13:52:51.830-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:52:51.829-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:52:52.117-0600] {processor.py:925} INFO - DAG(s) 'FirstDAG' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:52:52.140-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:52:52.140-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-18T13:52:52.172-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:52:52.171-0600] {dag.py:4180} INFO - Setting next_dagrun for FirstDAG to 2025-02-18 05:34:00+00:00, run_after=2025-02-18 05:35:00+00:00
[2025-02-18T13:52:52.219-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.406 seconds
[2025-02-18T13:53:08.365-0600] {processor.py:186} INFO - Started process (PID=99273) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:53:08.367-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T13:53:08.371-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:53:08.371-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:53:08.387-0600] {processor.py:925} INFO - DAG(s) 'FirstDAG' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:53:08.423-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:53:08.422-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-18T13:53:08.465-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:53:08.465-0600] {dag.py:4180} INFO - Setting next_dagrun for FirstDAG to 2025-02-18 05:34:00+00:00, run_after=2025-02-18 05:35:00+00:00
[2025-02-18T13:53:08.514-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.162 seconds
[2025-02-18T13:53:14.592-0600] {processor.py:186} INFO - Started process (PID=99336) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:53:14.594-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T13:53:14.599-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:53:14.598-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:53:14.618-0600] {processor.py:925} INFO - DAG(s) 'FirstDAG' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:53:14.773-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:53:14.773-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-18T13:53:14.805-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:53:14.805-0600] {dag.py:4180} INFO - Setting next_dagrun for FirstDAG to 2025-02-18 05:30:00+00:00, run_after=2025-02-18 05:35:00+00:00
[2025-02-18T13:53:14.859-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.278 seconds
[2025-02-18T13:53:45.837-0600] {processor.py:186} INFO - Started process (PID=99711) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:53:45.841-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T13:53:45.846-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:53:45.845-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:53:45.866-0600] {processor.py:925} INFO - DAG(s) 'FirstDAG' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:53:45.914-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:53:45.914-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-18T13:53:45.962-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:53:45.962-0600] {dag.py:4180} INFO - Setting next_dagrun for FirstDAG to 2025-02-18 05:30:00+00:00, run_after=2025-02-18 05:35:00+00:00
[2025-02-18T13:53:46.014-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.188 seconds
[2025-02-18T13:54:19.220-0600] {processor.py:186} INFO - Started process (PID=100079) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:54:19.221-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T13:54:19.226-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:54:19.225-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:54:19.242-0600] {processor.py:925} INFO - DAG(s) 'FirstDAG' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:54:19.290-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:54:19.289-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-18T13:54:19.342-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:54:19.341-0600] {dag.py:4180} INFO - Setting next_dagrun for FirstDAG to 2025-02-18 05:40:00+00:00, run_after=2025-02-18 05:45:00+00:00
[2025-02-18T13:54:19.388-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.183 seconds
[2025-02-18T13:54:51.410-0600] {processor.py:186} INFO - Started process (PID=100728) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:54:51.414-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T13:54:51.428-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:54:51.427-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:54:51.446-0600] {processor.py:925} INFO - DAG(s) 'FirstDAG' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:54:51.489-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:54:51.488-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-18T13:54:51.522-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:54:51.522-0600] {dag.py:4180} INFO - Setting next_dagrun for FirstDAG to 2025-02-18 06:25:00+00:00, run_after=2025-02-18 06:30:00+00:00
[2025-02-18T13:54:51.557-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.166 seconds
[2025-02-18T13:55:21.657-0600] {processor.py:186} INFO - Started process (PID=101294) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:55:21.659-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T13:55:21.661-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:55:21.661-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:55:21.674-0600] {processor.py:925} INFO - DAG(s) 'FirstDAG' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:55:21.714-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:55:21.714-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-18T13:55:21.760-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:55:21.759-0600] {dag.py:4180} INFO - Setting next_dagrun for FirstDAG to 2025-02-18 07:05:00+00:00, run_after=2025-02-18 07:10:00+00:00
[2025-02-18T13:55:21.799-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.152 seconds
[2025-02-18T13:55:52.211-0600] {processor.py:186} INFO - Started process (PID=101929) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:55:52.214-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T13:55:52.217-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:55:52.216-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:55:52.233-0600] {processor.py:925} INFO - DAG(s) 'FirstDAG' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:55:52.265-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:55:52.265-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-18T13:55:52.299-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:55:52.298-0600] {dag.py:4180} INFO - Setting next_dagrun for FirstDAG to 2025-02-18 07:45:00+00:00, run_after=2025-02-18 07:50:00+00:00
[2025-02-18T13:55:52.331-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.131 seconds
[2025-02-18T13:56:23.808-0600] {processor.py:186} INFO - Started process (PID=102689) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:56:23.809-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T13:56:23.813-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:56:23.812-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:56:23.828-0600] {processor.py:925} INFO - DAG(s) 'FirstDAG' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:56:23.859-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:56:23.859-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-18T13:56:23.900-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:56:23.900-0600] {dag.py:4180} INFO - Setting next_dagrun for FirstDAG to 2025-02-18 08:25:00+00:00, run_after=2025-02-18 08:30:00+00:00
[2025-02-18T13:56:23.941-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.148 seconds
[2025-02-18T13:56:56.040-0600] {processor.py:186} INFO - Started process (PID=103307) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:56:56.044-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T13:56:56.048-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:56:56.048-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:56:56.064-0600] {processor.py:925} INFO - DAG(s) 'FirstDAG' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:56:56.095-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:56:56.095-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-18T13:56:56.138-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:56:56.138-0600] {dag.py:4180} INFO - Setting next_dagrun for FirstDAG to 2025-02-18 09:05:00+00:00, run_after=2025-02-18 09:10:00+00:00
[2025-02-18T13:56:56.175-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.146 seconds
[2025-02-18T13:57:27.085-0600] {processor.py:186} INFO - Started process (PID=104019) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:57:27.087-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T13:57:27.090-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:57:27.089-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:57:27.105-0600] {processor.py:925} INFO - DAG(s) 'FirstDAG' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:57:27.133-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:57:27.133-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-18T13:57:27.167-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:57:27.167-0600] {dag.py:4180} INFO - Setting next_dagrun for FirstDAG to 2025-02-18 09:45:00+00:00, run_after=2025-02-18 09:50:00+00:00
[2025-02-18T13:57:27.212-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.135 seconds
[2025-02-18T13:57:51.421-0600] {processor.py:186} INFO - Started process (PID=104495) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:57:51.424-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T13:57:51.429-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:57:51.428-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:57:51.443-0600] {processor.py:925} INFO - DAG(s) 'FirstDAG' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:57:51.480-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:57:51.480-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-18T13:57:51.518-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:57:51.517-0600] {dag.py:4180} INFO - Setting next_dagrun for FirstDAG to 2025-02-18 10:15:00+00:00, run_after=2025-02-18 10:20:00+00:00
[2025-02-18T13:57:51.551-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.141 seconds
[2025-02-18T13:58:24.443-0600] {processor.py:186} INFO - Started process (PID=105077) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:58:24.446-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T13:58:24.450-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:58:24.449-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:58:24.466-0600] {processor.py:925} INFO - DAG(s) 'FirstDAG' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:58:24.500-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:58:24.500-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-18T13:58:24.537-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:58:24.537-0600] {dag.py:4180} INFO - Setting next_dagrun for FirstDAG to 2025-02-18 10:55:00+00:00, run_after=2025-02-18 11:00:00+00:00
[2025-02-18T13:58:24.572-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.139 seconds
[2025-02-18T13:58:57.488-0600] {processor.py:186} INFO - Started process (PID=105828) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:58:57.490-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T13:58:57.493-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:58:57.493-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:58:57.507-0600] {processor.py:925} INFO - DAG(s) 'FirstDAG' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:58:57.536-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:58:57.536-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-18T13:58:57.569-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:58:57.569-0600] {dag.py:4180} INFO - Setting next_dagrun for FirstDAG to 2025-02-18 11:35:00+00:00, run_after=2025-02-18 11:40:00+00:00
[2025-02-18T13:58:57.602-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.126 seconds
[2025-02-18T13:59:27.815-0600] {processor.py:186} INFO - Started process (PID=106575) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:59:27.817-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T13:59:27.823-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:59:27.821-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:59:27.844-0600] {processor.py:925} INFO - DAG(s) 'FirstDAG' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T13:59:27.897-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:59:27.896-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-18T13:59:27.947-0600] {logging_mixin.py:190} INFO - [2025-02-18T13:59:27.947-0600] {dag.py:4180} INFO - Setting next_dagrun for FirstDAG to 2025-02-18 12:10:00+00:00, run_after=2025-02-18 12:15:00+00:00
[2025-02-18T13:59:27.989-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.185 seconds
[2025-02-18T14:00:00.699-0600] {processor.py:186} INFO - Started process (PID=107318) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:00:00.702-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T14:00:00.705-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:00:00.704-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:00:00.725-0600] {processor.py:925} INFO - DAG(s) 'FirstDAG' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:00:00.759-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:00:00.759-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-18T14:00:00.804-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:00:00.804-0600] {dag.py:4180} INFO - Setting next_dagrun for FirstDAG to 2025-02-18 12:50:00+00:00, run_after=2025-02-18 12:55:00+00:00
[2025-02-18T14:00:00.851-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.165 seconds
[2025-02-18T14:00:33.179-0600] {processor.py:186} INFO - Started process (PID=108076) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:00:33.182-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T14:00:33.185-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:00:33.184-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:00:33.201-0600] {processor.py:925} INFO - DAG(s) 'FirstDAG' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:00:33.235-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:00:33.235-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-18T14:00:33.271-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:00:33.271-0600] {dag.py:4180} INFO - Setting next_dagrun for FirstDAG to 2025-02-18 13:30:00+00:00, run_after=2025-02-18 13:35:00+00:00
[2025-02-18T14:00:33.307-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.136 seconds
[2025-02-18T14:01:03.419-0600] {processor.py:186} INFO - Started process (PID=108701) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:01:03.422-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T14:01:03.426-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:01:03.425-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:01:03.444-0600] {processor.py:925} INFO - DAG(s) 'FirstDAG' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:01:03.484-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:01:03.483-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-18T14:01:03.520-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:01:03.520-0600] {dag.py:4180} INFO - Setting next_dagrun for FirstDAG to 2025-02-18 13:55:00+00:00, run_after=2025-02-18 14:00:00+00:00
[2025-02-18T14:01:03.558-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.148 seconds
[2025-02-18T14:01:34.234-0600] {processor.py:186} INFO - Started process (PID=109221) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:01:34.237-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T14:01:34.242-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:01:34.241-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:01:34.258-0600] {processor.py:925} INFO - DAG(s) 'FirstDAG' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:01:34.295-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:01:34.295-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-18T14:01:34.340-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:01:34.340-0600] {dag.py:4180} INFO - Setting next_dagrun for FirstDAG to 2025-02-18 13:55:00+00:00, run_after=2025-02-18 14:00:00+00:00
[2025-02-18T14:01:34.381-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.158 seconds
[2025-02-18T14:02:04.957-0600] {processor.py:186} INFO - Started process (PID=109701) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:02:04.961-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T14:02:04.964-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:02:04.963-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:02:04.978-0600] {processor.py:925} INFO - DAG(s) 'FirstDAG' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:02:05.017-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:02:05.016-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-18T14:02:05.061-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:02:05.061-0600] {dag.py:4180} INFO - Setting next_dagrun for FirstDAG to 2025-02-18 13:55:00+00:00, run_after=2025-02-18 14:00:00+00:00
[2025-02-18T14:02:05.096-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.151 seconds
[2025-02-18T14:02:35.320-0600] {processor.py:186} INFO - Started process (PID=110092) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:02:35.324-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T14:02:35.329-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:02:35.328-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:02:35.345-0600] {processor.py:925} INFO - DAG(s) 'FirstDAG' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:02:35.385-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:02:35.385-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-18T14:02:35.429-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:02:35.428-0600] {dag.py:4180} INFO - Setting next_dagrun for FirstDAG to 2025-02-18 13:55:00+00:00, run_after=2025-02-18 14:00:00+00:00
[2025-02-18T14:02:35.475-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.173 seconds
[2025-02-18T14:03:06.090-0600] {processor.py:186} INFO - Started process (PID=110405) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:03:06.093-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T14:03:06.097-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:03:06.096-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:03:06.114-0600] {processor.py:925} INFO - DAG(s) 'FirstDAG' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:03:06.199-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:03:06.198-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-18T14:03:06.293-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:03:06.292-0600] {dag.py:4180} INFO - Setting next_dagrun for FirstDAG to 2025-02-18 13:55:00+00:00, run_after=2025-02-18 14:00:00+00:00
[2025-02-18T14:03:06.340-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.265 seconds
[2025-02-18T14:03:36.851-0600] {processor.py:186} INFO - Started process (PID=110773) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:03:36.856-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T14:03:36.861-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:03:36.859-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:03:36.880-0600] {processor.py:925} INFO - DAG(s) 'FirstDAG' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:03:36.923-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:03:36.923-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-18T14:03:36.971-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:03:36.971-0600] {dag.py:4180} INFO - Setting next_dagrun for FirstDAG to 2025-02-18 13:55:00+00:00, run_after=2025-02-18 14:00:00+00:00
[2025-02-18T14:03:37.017-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.184 seconds
[2025-02-18T14:04:07.581-0600] {processor.py:186} INFO - Started process (PID=111078) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:04:07.584-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T14:04:07.589-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:04:07.588-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:04:07.606-0600] {processor.py:925} INFO - DAG(s) 'FirstDAG' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:04:07.654-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:04:07.653-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-18T14:04:07.703-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:04:07.702-0600] {dag.py:4180} INFO - Setting next_dagrun for FirstDAG to 2025-02-18 13:55:00+00:00, run_after=2025-02-18 14:00:00+00:00
[2025-02-18T14:04:07.748-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.181 seconds
[2025-02-18T14:04:38.305-0600] {processor.py:186} INFO - Started process (PID=111419) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:04:38.306-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T14:04:38.310-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:04:38.310-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:04:38.327-0600] {processor.py:925} INFO - DAG(s) 'FirstDAG' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:04:38.371-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:04:38.370-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-18T14:04:38.422-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:04:38.422-0600] {dag.py:4180} INFO - Setting next_dagrun for FirstDAG to 2025-02-18 13:55:00+00:00, run_after=2025-02-18 14:00:00+00:00
[2025-02-18T14:04:38.469-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.178 seconds
[2025-02-18T14:05:09.001-0600] {processor.py:186} INFO - Started process (PID=111859) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:05:09.003-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T14:05:09.006-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:05:09.005-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:05:09.019-0600] {processor.py:925} INFO - DAG(s) 'FirstDAG' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:05:09.056-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:05:09.056-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-18T14:05:09.102-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:05:09.101-0600] {dag.py:4180} INFO - Setting next_dagrun for FirstDAG to 2025-02-18 13:55:00+00:00, run_after=2025-02-18 14:00:00+00:00
[2025-02-18T14:05:09.140-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.151 seconds
[2025-02-18T14:05:22.368-0600] {processor.py:186} INFO - Started process (PID=112025) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:05:22.374-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T14:05:22.383-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:05:22.381-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:05:22.433-0600] {processor.py:925} INFO - DAG(s) 'FirstDAG' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:05:22.500-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:05:22.500-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-18T14:05:22.544-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:05:22.543-0600] {dag.py:4180} INFO - Setting next_dagrun for FirstDAG to 2025-02-18 13:55:00+00:00, run_after=2025-02-18 14:00:00+00:00
[2025-02-18T14:05:22.583-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.239 seconds
[2025-02-18T14:05:53.748-0600] {processor.py:186} INFO - Started process (PID=112396) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:05:53.750-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T14:05:53.752-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:05:53.752-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:05:53.826-0600] {processor.py:925} INFO - DAG(s) 'FirstDAG' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:05:53.932-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:05:53.931-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-18T14:05:54.067-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:05:54.067-0600] {dag.py:4180} INFO - Setting next_dagrun for FirstDAG to 2025-02-18 13:55:00+00:00, run_after=2025-02-18 14:00:00+00:00
[2025-02-18T14:05:54.147-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.439 seconds
[2025-02-18T14:06:08.399-0600] {processor.py:186} INFO - Started process (PID=112547) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:06:08.408-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T14:06:08.422-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:06:08.422-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:06:08.468-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:06:08.456-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dags.py", line 10, in <module>
    producer = Producer(conf)
cimpl.KafkaException: KafkaError{code=_INVALID_ARG,val=-186,str="No such configuration property: "bootstrap-server""}
[2025-02-18T14:06:08.471-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:06:08.602-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.261 seconds
[2025-02-18T14:06:37.805-0600] {processor.py:186} INFO - Started process (PID=112967) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:06:37.808-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T14:06:37.812-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:06:37.811-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:06:37.820-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:06:37.817-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 879, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1017, in get_code
  File "<frozen importlib._bootstrap_external>", line 947, in source_to_code
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dags.py", line 16
    with DAG(
    ^^^^
IndentationError: expected an indented block after function definition on line 13
[2025-02-18T14:06:37.822-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:06:37.866-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.078 seconds
[2025-02-18T14:06:40.741-0600] {processor.py:186} INFO - Started process (PID=112979) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:06:40.743-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T14:06:40.747-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:06:40.746-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:06:40.782-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:06:40.779-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dags.py", line 10, in <module>
    producer = Producer(conf)
cimpl.KafkaException: KafkaError{code=_INVALID_ARG,val=-186,str="No such configuration property: "bootstrap-server""}
[2025-02-18T14:06:40.783-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:06:40.859-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.134 seconds
[2025-02-18T14:07:05.625-0600] {processor.py:186} INFO - Started process (PID=113232) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:07:05.639-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T14:07:05.676-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:07:05.673-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:07:05.685-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:07:05.683-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 879, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1017, in get_code
  File "<frozen importlib._bootstrap_external>", line 947, in source_to_code
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dags.py", line 16
    with DAG(
    ^^^^
IndentationError: expected an indented block after function definition on line 13
[2025-02-18T14:07:05.686-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:07:05.722-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.198 seconds
[2025-02-18T14:07:17.702-0600] {processor.py:186} INFO - Started process (PID=113347) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:07:17.705-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T14:07:17.711-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:07:17.710-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:07:17.718-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:07:17.716-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 879, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1017, in get_code
  File "<frozen importlib._bootstrap_external>", line 947, in source_to_code
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dags.py", line 17
    with DAG(
    ^^^^
IndentationError: expected an indented block after function definition on line 13
[2025-02-18T14:07:17.718-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:07:17.807-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.174 seconds
[2025-02-18T14:07:21.159-0600] {processor.py:186} INFO - Started process (PID=113392) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:07:21.162-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T14:07:21.176-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:07:21.174-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:07:21.206-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:07:21.204-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dags.py", line 10, in <module>
    producer = Producer(conf)
cimpl.KafkaException: KafkaError{code=_INVALID_ARG,val=-186,str="No such configuration property: "bootstrap-server""}
[2025-02-18T14:07:21.207-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:07:21.305-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.199 seconds
[2025-02-18T14:07:50.077-0600] {processor.py:186} INFO - Started process (PID=113752) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:07:50.078-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T14:07:50.082-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:07:50.082-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:07:50.120-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:07:50.115-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dags.py", line 10, in <module>
    producer = Producer(conf)
cimpl.KafkaException: KafkaError{code=_INVALID_ARG,val=-186,str="No such configuration property: "bootstrap-server""}
[2025-02-18T14:07:50.122-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:07:50.161-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.105 seconds
[2025-02-18T14:08:20.802-0600] {processor.py:186} INFO - Started process (PID=114117) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:08:20.811-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T14:08:20.819-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:08:20.817-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:08:20.842-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:08:20.839-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dags.py", line 10, in <module>
    producer = Producer(conf)
cimpl.KafkaException: KafkaError{code=_INVALID_ARG,val=-186,str="No such configuration property: "bootstrap-server""}
[2025-02-18T14:08:20.843-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:08:20.908-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.149 seconds
[2025-02-18T14:08:51.195-0600] {processor.py:186} INFO - Started process (PID=114484) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:08:51.197-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T14:08:51.204-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:08:51.201-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:08:51.237-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:08:51.235-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dags.py", line 10, in <module>
    producer = Producer(conf)
cimpl.KafkaException: KafkaError{code=_INVALID_ARG,val=-186,str="No such configuration property: "bootstrap-server""}
[2025-02-18T14:08:51.239-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:08:51.301-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.127 seconds
[2025-02-18T14:08:54.235-0600] {processor.py:186} INFO - Started process (PID=114520) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:08:54.239-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T14:08:54.241-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:08:54.241-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:08:54.258-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:08:54.256-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dags.py", line 10, in <module>
    producer = Producer(conf)
cimpl.KafkaException: KafkaError{code=_INVALID_ARG,val=-186,str="No such configuration property: "bootstrap-server""}
[2025-02-18T14:08:54.259-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:08:54.305-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.086 seconds
[2025-02-18T14:09:15.617-0600] {processor.py:186} INFO - Started process (PID=114730) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:09:15.619-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T14:09:15.623-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:09:15.622-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:09:15.639-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:09:15.638-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dags.py", line 10, in <module>
    producer = Producer(conf)
cimpl.KafkaException: KafkaError{code=_INVALID_ARG,val=-186,str="No such configuration property: "bootstrap-server""}
[2025-02-18T14:09:15.640-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:09:15.689-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.084 seconds
[2025-02-18T14:09:29.857-0600] {processor.py:186} INFO - Started process (PID=114941) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:09:29.860-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T14:09:29.863-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:09:29.862-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:09:29.881-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:09:29.879-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dags.py", line 10, in <module>
    producer = Producer(conf)
cimpl.KafkaException: KafkaError{code=_INVALID_ARG,val=-186,str="No such configuration property: "bootstrap-server""}
[2025-02-18T14:09:29.882-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:09:29.924-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.086 seconds
[2025-02-18T14:09:36.022-0600] {processor.py:186} INFO - Started process (PID=114996) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:09:36.025-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T14:09:36.030-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:09:36.029-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:09:36.069-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:09:36.065-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dags.py", line 10, in <module>
    producer = Producer(conf)
cimpl.KafkaException: KafkaError{code=_INVALID_ARG,val=-186,str="No such configuration property: "bootstrap-server""}
[2025-02-18T14:09:36.071-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:09:36.135-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.146 seconds
[2025-02-18T14:10:06.453-0600] {processor.py:186} INFO - Started process (PID=115377) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:10:06.457-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T14:10:06.461-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:10:06.460-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:10:06.476-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:10:06.474-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dags.py", line 10, in <module>
    producer = Producer(conf)
cimpl.KafkaException: KafkaError{code=_INVALID_ARG,val=-186,str="No such configuration property: "bootstrap-server""}
[2025-02-18T14:10:06.477-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:10:06.537-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.099 seconds
[2025-02-18T14:10:36.966-0600] {processor.py:186} INFO - Started process (PID=115769) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:10:36.976-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T14:10:36.981-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:10:36.980-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:10:37.013-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:10:37.011-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dags.py", line 10, in <module>
    producer = Producer(conf)
cimpl.KafkaException: KafkaError{code=_INVALID_ARG,val=-186,str="No such configuration property: "bootstrap-server""}
[2025-02-18T14:10:37.014-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:10:37.087-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.159 seconds
[2025-02-18T14:11:07.416-0600] {processor.py:186} INFO - Started process (PID=116209) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:11:07.419-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T14:11:07.423-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:11:07.422-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:11:07.467-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:11:07.460-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dags.py", line 10, in <module>
    producer = Producer(conf)
cimpl.KafkaException: KafkaError{code=_INVALID_ARG,val=-186,str="No such configuration property: "bootstrap-server""}
[2025-02-18T14:11:07.469-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:11:07.525-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.124 seconds
[2025-02-18T14:11:37.910-0600] {processor.py:186} INFO - Started process (PID=117019) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:11:37.913-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T14:11:37.915-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:11:37.914-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:11:37.930-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:11:37.928-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dags.py", line 10, in <module>
    producer = Producer(conf)
cimpl.KafkaException: KafkaError{code=_INVALID_ARG,val=-186,str="No such configuration property: "bootstrap-server""}
[2025-02-18T14:11:37.930-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:11:37.959-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.061 seconds
[2025-02-18T14:12:08.416-0600] {processor.py:186} INFO - Started process (PID=117227) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:12:08.420-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T14:12:08.424-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:12:08.422-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:12:08.450-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:12:08.448-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dags.py", line 10, in <module>
    producer = Producer(conf)
cimpl.KafkaException: KafkaError{code=_INVALID_ARG,val=-186,str="No such configuration property: "bootstrap-server""}
[2025-02-18T14:12:08.450-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:12:08.520-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.122 seconds
[2025-02-18T14:12:11.369-0600] {processor.py:186} INFO - Started process (PID=117246) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:12:11.374-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T14:12:11.377-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:12:11.376-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:12:11.424-0600] {processor.py:925} INFO - DAG(s) 'FirstDAG' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:12:11.829-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:12:11.828-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-18T14:12:11.867-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:12:11.867-0600] {dag.py:4180} INFO - Setting next_dagrun for FirstDAG to 2025-02-18 13:55:00+00:00, run_after=2025-02-18 14:00:00+00:00
[2025-02-18T14:12:11.913-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.558 seconds
[2025-02-18T14:12:42.482-0600] {processor.py:186} INFO - Started process (PID=117966) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:12:42.484-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T14:12:42.486-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:12:42.485-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:12:42.521-0600] {processor.py:925} INFO - DAG(s) 'FirstDAG' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:12:42.565-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:12:42.564-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-18T14:12:42.603-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:12:42.602-0600] {dag.py:4180} INFO - Setting next_dagrun for FirstDAG to 2025-02-18 14:30:00+00:00, run_after=2025-02-18 14:35:00+00:00
[2025-02-18T14:12:42.640-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.172 seconds
[2025-02-18T14:13:15.785-0600] {processor.py:186} INFO - Started process (PID=118769) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:13:15.787-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T14:13:15.789-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:13:15.789-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:13:15.819-0600] {processor.py:925} INFO - DAG(s) 'FirstDAG' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:13:15.848-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:13:15.848-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-18T14:13:15.882-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:13:15.882-0600] {dag.py:4180} INFO - Setting next_dagrun for FirstDAG to 2025-02-18 15:10:00+00:00, run_after=2025-02-18 15:15:00+00:00
[2025-02-18T14:13:15.922-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.151 seconds
[2025-02-18T14:13:48.427-0600] {processor.py:186} INFO - Started process (PID=120070) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:13:48.428-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T14:13:48.431-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:13:48.430-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:13:48.472-0600] {processor.py:925} INFO - DAG(s) 'FirstDAG' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:13:48.509-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:13:48.508-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-18T14:13:48.561-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:13:48.560-0600] {dag.py:4180} INFO - Setting next_dagrun for FirstDAG to 2025-02-18 15:50:00+00:00, run_after=2025-02-18 15:55:00+00:00
[2025-02-18T14:13:48.607-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.198 seconds
[2025-02-18T14:14:18.788-0600] {processor.py:186} INFO - Started process (PID=120669) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:14:18.791-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T14:14:18.793-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:14:18.792-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:14:18.840-0600] {processor.py:925} INFO - DAG(s) 'FirstDAG' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:14:18.886-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:14:18.885-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-18T14:14:18.925-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:14:18.925-0600] {dag.py:4180} INFO - Setting next_dagrun for FirstDAG to 2025-02-18 16:25:00+00:00, run_after=2025-02-18 16:30:00+00:00
[2025-02-18T14:14:18.958-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.187 seconds
[2025-02-18T14:14:49.752-0600] {processor.py:186} INFO - Started process (PID=121441) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:14:49.754-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T14:14:49.756-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:14:49.755-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:14:49.785-0600] {processor.py:925} INFO - DAG(s) 'FirstDAG' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:14:49.817-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:14:49.817-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-18T14:14:49.853-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:14:49.852-0600] {dag.py:4180} INFO - Setting next_dagrun for FirstDAG to 2025-02-18 17:05:00+00:00, run_after=2025-02-18 17:10:00+00:00
[2025-02-18T14:14:49.889-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.151 seconds
[2025-02-18T14:15:22.557-0600] {processor.py:186} INFO - Started process (PID=122193) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:15:22.560-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T14:15:22.562-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:15:22.562-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:15:22.593-0600] {processor.py:925} INFO - DAG(s) 'FirstDAG' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:15:22.626-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:15:22.625-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-18T14:15:22.668-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:15:22.667-0600] {dag.py:4180} INFO - Setting next_dagrun for FirstDAG to 2025-02-18 17:45:00+00:00, run_after=2025-02-18 17:50:00+00:00
[2025-02-18T14:15:22.710-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.166 seconds
[2025-02-18T14:15:55.636-0600] {processor.py:186} INFO - Started process (PID=123529) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:15:55.638-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T14:15:55.641-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:15:55.640-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:15:55.674-0600] {processor.py:925} INFO - DAG(s) 'FirstDAG' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:15:55.717-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:15:55.717-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-18T14:15:55.759-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:15:55.758-0600] {dag.py:4180} INFO - Setting next_dagrun for FirstDAG to 2025-02-18 18:25:00+00:00, run_after=2025-02-18 18:30:00+00:00
[2025-02-18T14:15:55.799-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.176 seconds
[2025-02-18T14:16:26.120-0600] {processor.py:186} INFO - Started process (PID=124164) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:16:26.122-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T14:16:26.126-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:16:26.125-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:16:26.169-0600] {processor.py:925} INFO - DAG(s) 'FirstDAG' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:16:26.202-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:16:26.202-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-18T14:16:26.235-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:16:26.235-0600] {dag.py:4180} INFO - Setting next_dagrun for FirstDAG to 2025-02-18 19:00:00+00:00, run_after=2025-02-18 19:05:00+00:00
[2025-02-18T14:16:26.269-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.175 seconds
[2025-02-18T14:16:49.550-0600] {processor.py:186} INFO - Started process (PID=124615) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:16:49.553-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T14:16:49.554-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:16:49.554-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:16:49.590-0600] {processor.py:925} INFO - DAG(s) 'FirstDAG' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:16:49.832-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:16:49.832-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-18T14:16:49.858-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:16:49.857-0600] {dag.py:4180} INFO - Setting next_dagrun for FirstDAG to 2025-02-18 00:00:00+00:00, run_after=2025-02-19 00:00:00+00:00
[2025-02-18T14:16:49.894-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.358 seconds
[2025-02-18T14:17:20.409-0600] {processor.py:186} INFO - Started process (PID=125105) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:17:20.411-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T14:17:20.414-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:17:20.413-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:17:20.456-0600] {processor.py:925} INFO - DAG(s) 'FirstDAG' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:17:20.497-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:17:20.497-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-18T14:17:20.537-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:17:20.536-0600] {dag.py:4180} INFO - Setting next_dagrun for FirstDAG to 2025-02-18 00:00:00+00:00, run_after=2025-02-19 00:00:00+00:00
[2025-02-18T14:17:20.585-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.191 seconds
[2025-02-18T14:17:51.094-0600] {processor.py:186} INFO - Started process (PID=125476) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:17:51.097-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T14:17:51.100-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:17:51.099-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:17:51.138-0600] {processor.py:925} INFO - DAG(s) 'FirstDAG' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:17:51.190-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:17:51.189-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-18T14:17:51.230-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:17:51.230-0600] {dag.py:4180} INFO - Setting next_dagrun for FirstDAG to 2025-02-18 00:00:00+00:00, run_after=2025-02-19 00:00:00+00:00
[2025-02-18T14:17:51.283-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.202 seconds
[2025-02-18T14:18:21.897-0600] {processor.py:186} INFO - Started process (PID=126446) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:18:21.900-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T14:18:21.902-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:18:21.901-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:18:21.930-0600] {processor.py:925} INFO - DAG(s) 'FirstDAG' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:18:21.966-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:18:21.965-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-18T14:18:22.017-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:18:22.016-0600] {dag.py:4180} INFO - Setting next_dagrun for FirstDAG to 2025-02-18 00:00:00+00:00, run_after=2025-02-19 00:00:00+00:00
[2025-02-18T14:18:22.058-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.173 seconds
[2025-02-18T14:18:52.510-0600] {processor.py:186} INFO - Started process (PID=126830) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:18:52.514-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T14:18:52.517-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:18:52.516-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:18:52.565-0600] {processor.py:925} INFO - DAG(s) 'FirstDAG' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:18:52.616-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:18:52.615-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-18T14:18:52.660-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:18:52.660-0600] {dag.py:4180} INFO - Setting next_dagrun for FirstDAG to 2025-02-18 00:00:00+00:00, run_after=2025-02-19 00:00:00+00:00
[2025-02-18T14:18:52.713-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.222 seconds
[2025-02-18T14:19:23.362-0600] {processor.py:186} INFO - Started process (PID=127020) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:19:23.364-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T14:19:23.367-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:19:23.366-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:19:23.406-0600] {processor.py:925} INFO - DAG(s) 'FirstDAG' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:19:23.442-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:19:23.441-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-18T14:19:23.507-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:19:23.506-0600] {dag.py:4180} INFO - Setting next_dagrun for FirstDAG to 2025-02-18 00:00:00+00:00, run_after=2025-02-19 00:00:00+00:00
[2025-02-18T14:19:23.559-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.218 seconds
[2025-02-18T14:19:53.782-0600] {processor.py:186} INFO - Started process (PID=127274) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:19:53.786-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T14:19:53.790-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:19:53.789-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:19:53.842-0600] {processor.py:925} INFO - DAG(s) 'FirstDAG' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:19:53.905-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:19:53.905-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-18T14:19:53.961-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:19:53.961-0600] {dag.py:4180} INFO - Setting next_dagrun for FirstDAG to 2025-02-18 00:00:00+00:00, run_after=2025-02-19 00:00:00+00:00
[2025-02-18T14:19:54.016-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.256 seconds
[2025-02-18T14:20:24.229-0600] {processor.py:186} INFO - Started process (PID=127438) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:20:24.230-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T14:20:24.233-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:20:24.232-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:20:24.277-0600] {processor.py:925} INFO - DAG(s) 'FirstDAG' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:20:24.332-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:20:24.331-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-18T14:20:24.379-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:20:24.379-0600] {dag.py:4180} INFO - Setting next_dagrun for FirstDAG to 2025-02-18 00:00:00+00:00, run_after=2025-02-19 00:00:00+00:00
[2025-02-18T14:20:24.420-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.211 seconds
[2025-02-18T14:20:54.755-0600] {processor.py:186} INFO - Started process (PID=127718) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:20:54.771-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T14:20:54.778-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:20:54.777-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:20:54.867-0600] {processor.py:925} INFO - DAG(s) 'FirstDAG' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:20:54.914-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:20:54.913-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-18T14:20:54.959-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:20:54.958-0600] {dag.py:4180} INFO - Setting next_dagrun for FirstDAG to 2025-02-18 00:00:00+00:00, run_after=2025-02-19 00:00:00+00:00
[2025-02-18T14:20:55.001-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.281 seconds
[2025-02-18T14:21:25.247-0600] {processor.py:186} INFO - Started process (PID=128086) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:21:25.249-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T14:21:25.253-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:21:25.251-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:21:25.331-0600] {processor.py:925} INFO - DAG(s) 'FirstDAG' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:21:25.389-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:21:25.389-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-18T14:21:25.452-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:21:25.451-0600] {dag.py:4180} INFO - Setting next_dagrun for FirstDAG to 2025-02-18 00:00:00+00:00, run_after=2025-02-19 00:00:00+00:00
[2025-02-18T14:21:25.711-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.520 seconds
[2025-02-18T14:21:55.958-0600] {processor.py:186} INFO - Started process (PID=128516) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:21:55.961-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T14:21:55.966-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:21:55.965-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:21:56.022-0600] {processor.py:925} INFO - DAG(s) 'FirstDAG' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:21:56.198-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:21:56.197-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-18T14:21:56.382-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:21:56.380-0600] {dag.py:4180} INFO - Setting next_dagrun for FirstDAG to 2025-02-18 00:00:00+00:00, run_after=2025-02-19 00:00:00+00:00
[2025-02-18T14:21:56.491-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.563 seconds
[2025-02-18T14:22:26.687-0600] {processor.py:186} INFO - Started process (PID=128826) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:22:26.690-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T14:22:26.695-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:22:26.694-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:22:26.750-0600] {processor.py:925} INFO - DAG(s) 'FirstDAG' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:22:26.873-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:22:26.872-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-18T14:22:26.921-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:22:26.920-0600] {dag.py:4180} INFO - Setting next_dagrun for FirstDAG to 2025-02-18 00:00:00+00:00, run_after=2025-02-19 00:00:00+00:00
[2025-02-18T14:22:26.983-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.316 seconds
[2025-02-18T14:22:57.224-0600] {processor.py:186} INFO - Started process (PID=129195) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:22:57.226-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T14:22:57.230-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:22:57.229-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:22:57.285-0600] {processor.py:925} INFO - DAG(s) 'FirstDAG' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:22:57.508-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:22:57.507-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-18T14:22:57.570-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:22:57.570-0600] {dag.py:4180} INFO - Setting next_dagrun for FirstDAG to 2025-02-18 00:00:00+00:00, run_after=2025-02-19 00:00:00+00:00
[2025-02-18T14:22:57.629-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.421 seconds
[2025-02-18T14:23:27.856-0600] {processor.py:186} INFO - Started process (PID=129504) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:23:27.859-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T14:23:27.865-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:23:27.864-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:23:27.912-0600] {processor.py:925} INFO - DAG(s) 'FirstDAG' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:23:27.972-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:23:27.972-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-18T14:23:28.038-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:23:28.037-0600] {dag.py:4180} INFO - Setting next_dagrun for FirstDAG to 2025-02-18 00:00:00+00:00, run_after=2025-02-19 00:00:00+00:00
[2025-02-18T14:23:28.093-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.252 seconds
[2025-02-18T14:23:58.276-0600] {processor.py:186} INFO - Started process (PID=129903) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:23:58.277-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T14:23:58.280-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:23:58.279-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:23:58.324-0600] {processor.py:925} INFO - DAG(s) 'FirstDAG' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:23:58.369-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:23:58.369-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-18T14:23:58.402-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:23:58.401-0600] {dag.py:4180} INFO - Setting next_dagrun for FirstDAG to 2025-02-18 00:00:00+00:00, run_after=2025-02-19 00:00:00+00:00
[2025-02-18T14:23:58.435-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.170 seconds
[2025-02-18T14:24:28.616-0600] {processor.py:186} INFO - Started process (PID=130236) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:24:28.620-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T14:24:28.622-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:24:28.622-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:24:28.652-0600] {processor.py:925} INFO - DAG(s) 'FirstDAG' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:24:28.684-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:24:28.683-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-18T14:24:28.719-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:24:28.719-0600] {dag.py:4180} INFO - Setting next_dagrun for FirstDAG to 2025-02-18 00:00:00+00:00, run_after=2025-02-19 00:00:00+00:00
[2025-02-18T14:24:28.765-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.164 seconds
[2025-02-18T14:24:58.898-0600] {processor.py:186} INFO - Started process (PID=130596) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:24:58.900-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T14:24:58.910-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:24:58.903-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:24:59.014-0600] {processor.py:925} INFO - DAG(s) 'FirstDAG' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:24:59.068-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:24:59.067-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-18T14:24:59.105-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:24:59.105-0600] {dag.py:4180} INFO - Setting next_dagrun for FirstDAG to 2025-02-18 00:00:00+00:00, run_after=2025-02-19 00:00:00+00:00
[2025-02-18T14:24:59.145-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.267 seconds
[2025-02-18T14:25:29.377-0600] {processor.py:186} INFO - Started process (PID=131057) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:25:29.381-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T14:25:29.384-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:25:29.383-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:25:29.525-0600] {processor.py:925} INFO - DAG(s) 'FirstDAG' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:25:29.667-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:25:29.665-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-18T14:25:29.739-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:25:29.739-0600] {dag.py:4180} INFO - Setting next_dagrun for FirstDAG to 2025-02-18 00:00:00+00:00, run_after=2025-02-19 00:00:00+00:00
[2025-02-18T14:25:29.797-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.480 seconds
[2025-02-18T14:25:59.973-0600] {processor.py:186} INFO - Started process (PID=131592) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:25:59.985-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T14:25:59.995-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:25:59.993-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:26:00.049-0600] {processor.py:925} INFO - DAG(s) 'FirstDAG' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:26:00.154-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:26:00.153-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-18T14:26:00.197-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:26:00.196-0600] {dag.py:4180} INFO - Setting next_dagrun for FirstDAG to 2025-02-18 00:00:00+00:00, run_after=2025-02-19 00:00:00+00:00
[2025-02-18T14:26:00.247-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.294 seconds
[2025-02-18T14:26:26.762-0600] {processor.py:186} INFO - Started process (PID=131856) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:26:26.764-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T14:26:26.766-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:26:26.765-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:26:26.822-0600] {processor.py:925} INFO - DAG(s) 'FirstDAG' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:26:26.869-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:26:26.869-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-18T14:26:26.951-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:26:26.950-0600] {dag.py:4180} INFO - Setting next_dagrun for FirstDAG to 2025-02-18 00:00:00+00:00, run_after=2025-02-19 00:00:00+00:00
[2025-02-18T14:26:27.012-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.274 seconds
[2025-02-18T14:26:57.523-0600] {processor.py:186} INFO - Started process (PID=132314) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:26:57.524-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T14:26:57.526-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:26:57.525-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:26:57.566-0600] {processor.py:925} INFO - DAG(s) 'FirstDAG' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:26:57.601-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:26:57.601-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-18T14:26:57.639-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:26:57.639-0600] {dag.py:4180} INFO - Setting next_dagrun for FirstDAG to 2025-02-18 00:00:00+00:00, run_after=2025-02-19 00:00:00+00:00
[2025-02-18T14:26:57.677-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.169 seconds
[2025-02-18T14:27:07.065-0600] {processor.py:186} INFO - Started process (PID=132419) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:27:07.070-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T14:27:07.074-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:27:07.072-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:27:07.124-0600] {processor.py:925} INFO - DAG(s) 'FirstDAG' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:27:07.171-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:27:07.171-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-18T14:27:07.211-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:27:07.210-0600] {dag.py:4180} INFO - Setting next_dagrun for FirstDAG to 2025-02-18 00:00:00+00:00, run_after=2025-02-19 00:00:00+00:00
[2025-02-18T14:27:07.256-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.219 seconds
[2025-02-18T14:27:37.572-0600] {processor.py:186} INFO - Started process (PID=132791) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:27:37.574-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T14:27:37.576-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:27:37.575-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:27:37.610-0600] {processor.py:925} INFO - DAG(s) 'FirstDAG' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:27:37.643-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:27:37.642-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-18T14:27:37.681-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:27:37.680-0600] {dag.py:4180} INFO - Setting next_dagrun for FirstDAG to 2025-02-18 00:00:00+00:00, run_after=2025-02-19 00:00:00+00:00
[2025-02-18T14:27:37.719-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.161 seconds
[2025-02-18T14:28:08.024-0600] {processor.py:186} INFO - Started process (PID=133099) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:28:08.025-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T14:28:08.028-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:28:08.027-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:28:08.060-0600] {processor.py:925} INFO - DAG(s) 'FirstDAG' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:28:08.102-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:28:08.102-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-18T14:28:08.144-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:28:08.143-0600] {dag.py:4180} INFO - Setting next_dagrun for FirstDAG to 2025-02-18 00:00:00+00:00, run_after=2025-02-19 00:00:00+00:00
[2025-02-18T14:28:08.188-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.178 seconds
[2025-02-18T14:28:13.139-0600] {processor.py:186} INFO - Started process (PID=133154) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:28:13.141-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T14:28:13.145-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:28:13.144-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:28:13.154-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:28:13.150-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 879, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1017, in get_code
  File "<frozen importlib._bootstrap_external>", line 947, in source_to_code
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dags.py", line 21
    producer.produce(f"Current time {datetime.now().strftime("%H:%M:%S")}")
                                                              ^
SyntaxError: f-string: unmatched '('
[2025-02-18T14:28:13.155-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:28:13.209-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.084 seconds
[2025-02-18T14:28:43.328-0600] {processor.py:186} INFO - Started process (PID=133519) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:28:43.330-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T14:28:43.332-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:28:43.332-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:28:43.337-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:28:43.336-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 879, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1017, in get_code
  File "<frozen importlib._bootstrap_external>", line 947, in source_to_code
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dags.py", line 21
    producer.produce(f"Current time {datetime.now().strftime("%H:%M:%S")}")
                                                              ^
SyntaxError: f-string: unmatched '('
[2025-02-18T14:28:43.337-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:28:43.367-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.052 seconds
[2025-02-18T14:28:52.313-0600] {processor.py:186} INFO - Started process (PID=133591) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:28:52.316-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T14:28:52.320-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:28:52.319-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:28:52.326-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:28:52.325-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 879, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1017, in get_code
  File "<frozen importlib._bootstrap_external>", line 947, in source_to_code
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dags.py", line 21
    producer.produce(f"Current time {datetime.now().strftime("%H:%M:%S")}")
                                                              ^
SyntaxError: f-string: unmatched '('
[2025-02-18T14:28:52.327-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:28:52.370-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.072 seconds
[2025-02-18T14:28:58.045-0600] {processor.py:186} INFO - Started process (PID=133668) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:28:58.048-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T14:28:58.050-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:28:58.050-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:28:58.055-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:28:58.054-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 879, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1017, in get_code
  File "<frozen importlib._bootstrap_external>", line 947, in source_to_code
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dags.py", line 21
    producer.produce(f"Current time {datetime.now().strftime("%H:%M:%S")}")
                                                              ^
SyntaxError: f-string: unmatched '('
[2025-02-18T14:28:58.056-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:28:58.088-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.055 seconds
[2025-02-18T14:29:28.428-0600] {processor.py:186} INFO - Started process (PID=134078) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:29:28.433-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T14:29:28.437-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:29:28.436-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:29:28.447-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:29:28.444-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 879, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1017, in get_code
  File "<frozen importlib._bootstrap_external>", line 947, in source_to_code
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dags.py", line 21
    producer.produce(f"Current time {datetime.now().strftime("%H:%M:%S")}")
                                                              ^
SyntaxError: f-string: unmatched '('
[2025-02-18T14:29:28.449-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:29:28.517-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.116 seconds
[2025-02-18T14:29:51.660-0600] {processor.py:186} INFO - Started process (PID=134385) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:29:51.673-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T14:29:51.681-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:29:51.680-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:29:51.687-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:29:51.686-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 879, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1017, in get_code
  File "<frozen importlib._bootstrap_external>", line 947, in source_to_code
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dags.py", line 22
    producer.produce(f"Current time {currenttime.strftime("%H:%M:%S")}")
                                                           ^
SyntaxError: f-string: unmatched '('
[2025-02-18T14:29:51.689-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:29:51.726-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.134 seconds
[2025-02-18T14:30:18.403-0600] {processor.py:186} INFO - Started process (PID=134871) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:30:18.405-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dags.py for tasks to queue
[2025-02-18T14:30:18.407-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:30:18.406-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:30:18.442-0600] {processor.py:925} INFO - DAG(s) 'FirstDAG' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dags.py
[2025-02-18T14:30:18.813-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:30:18.813-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-18T14:30:18.863-0600] {logging_mixin.py:190} INFO - [2025-02-18T14:30:18.862-0600] {dag.py:4180} INFO - Setting next_dagrun for FirstDAG to 2025-02-18 19:05:00+00:00, run_after=2025-02-18 19:10:00+00:00
[2025-02-18T14:30:18.915-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dags.py took 0.525 seconds
