[2025-03-03T13:05:18.778-0600] {processor.py:186} INFO - Started process (PID=25093) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:05:18.779-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:05:18.783-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:05:18.782-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:05:18.793-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:05:18.788-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 879, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1017, in get_code
  File "<frozen importlib._bootstrap_external>", line 947, in source_to_code
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py", line 17
    )
    ^
SyntaxError: invalid syntax
[2025-03-03T13:05:18.794-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:05:18.869-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.102 seconds
[2025-03-03T13:05:27.872-0600] {processor.py:186} INFO - Started process (PID=25163) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:05:27.873-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:05:27.876-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:05:27.876-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:05:27.881-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:05:27.880-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 879, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1017, in get_code
  File "<frozen importlib._bootstrap_external>", line 947, in source_to_code
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py", line 17
    )
     ^
SyntaxError: expected ':'
[2025-03-03T13:05:27.882-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:05:27.932-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.070 seconds
[2025-03-03T13:05:34.950-0600] {processor.py:186} INFO - Started process (PID=25225) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:05:34.952-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:05:34.955-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:05:34.955-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:05:34.961-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:05:34.960-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 879, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1017, in get_code
  File "<frozen importlib._bootstrap_external>", line 947, in source_to_code
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py", line 17
    ) as dag:
             ^
IndentationError: expected an indented block after 'with' statement on line 13
[2025-03-03T13:05:34.962-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:05:35.013-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.073 seconds
[2025-03-03T13:05:36.044-0600] {processor.py:186} INFO - Started process (PID=25234) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:05:36.045-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:05:36.050-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:05:36.049-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:05:36.055-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:05:36.054-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 879, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1017, in get_code
  File "<frozen importlib._bootstrap_external>", line 947, in source_to_code
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py", line 18
    
    ^
IndentationError: expected an indented block after 'with' statement on line 13
[2025-03-03T13:05:36.055-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:05:36.099-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.066 seconds
[2025-03-03T13:05:45.159-0600] {processor.py:186} INFO - Started process (PID=25312) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:05:45.161-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:05:45.164-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:05:45.163-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:05:45.170-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:05:45.169-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py", line 13, in <module>
    with DAG(
TypeError: DAG.__init__() got an unexpected keyword argument 'schedule_interaval'
[2025-03-03T13:05:45.171-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:05:45.217-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.067 seconds
[2025-03-03T13:05:54.631-0600] {processor.py:186} INFO - Started process (PID=25412) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:05:54.632-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:05:54.636-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:05:54.635-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:05:54.643-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:05:54.642-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py", line 13, in <module>
    with DAG(
TypeError: DAG.__init__() got an unexpected keyword argument 'schedule_interaval'
[2025-03-03T13:05:54.644-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:05:54.685-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.066 seconds
[2025-03-03T13:06:25.040-0600] {processor.py:186} INFO - Started process (PID=25665) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:06:25.045-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:06:25.052-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:06:25.051-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:06:25.062-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:06:25.060-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py", line 13, in <module>
    with DAG(
TypeError: DAG.__init__() got an unexpected keyword argument 'schedule_interaval'
[2025-03-03T13:06:25.063-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:06:25.145-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.121 seconds
[2025-03-03T13:06:55.490-0600] {processor.py:186} INFO - Started process (PID=25895) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:06:55.492-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:06:55.496-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:06:55.495-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:06:55.500-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:06:55.499-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py", line 13, in <module>
    with DAG(
TypeError: DAG.__init__() got an unexpected keyword argument 'schedule_interaval'
[2025-03-03T13:06:55.501-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:06:55.543-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.063 seconds
[2025-03-03T13:07:25.883-0600] {processor.py:186} INFO - Started process (PID=26560) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:07:25.885-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:07:25.889-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:07:25.889-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:07:25.896-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:07:25.895-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py", line 13, in <module>
    with DAG(
TypeError: DAG.__init__() got an unexpected keyword argument 'schedule_interaval'
[2025-03-03T13:07:25.897-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:07:25.965-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.093 seconds
[2025-03-03T13:07:56.304-0600] {processor.py:186} INFO - Started process (PID=26866) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:07:56.306-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:07:56.312-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:07:56.311-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:07:56.318-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:07:56.317-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py", line 13, in <module>
    with DAG(
TypeError: DAG.__init__() got an unexpected keyword argument 'schedule_interaval'
[2025-03-03T13:07:56.319-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:07:56.364-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.071 seconds
[2025-03-03T13:08:22.308-0600] {processor.py:186} INFO - Started process (PID=27413) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:08:22.311-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:08:22.316-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:08:22.315-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:08:22.323-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:08:22.321-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py", line 13, in <module>
    with DAG(
TypeError: DAG.__init__() got an unexpected keyword argument 'schedule_interaval'
[2025-03-03T13:08:22.324-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:08:22.378-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.082 seconds
[2025-03-03T13:08:52.709-0600] {processor.py:186} INFO - Started process (PID=28683) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:08:52.712-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:08:52.717-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:08:52.717-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:08:52.729-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:08:52.725-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py", line 13, in <module>
    with DAG(
TypeError: DAG.__init__() got an unexpected keyword argument 'schedule_interaval'
[2025-03-03T13:08:52.730-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:08:52.826-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.136 seconds
[2025-03-03T13:09:23.220-0600] {processor.py:186} INFO - Started process (PID=29364) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:09:23.222-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:09:23.226-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:09:23.225-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:09:23.251-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:09:23.248-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py", line 13, in <module>
    with DAG(
TypeError: DAG.__init__() got an unexpected keyword argument 'schedule_interaval'
[2025-03-03T13:09:23.252-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:09:23.357-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.159 seconds
[2025-03-03T13:09:44.589-0600] {processor.py:186} INFO - Started process (PID=29506) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:09:44.592-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:09:44.601-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:09:44.599-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:09:44.627-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:09:44.617-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py", line 13, in <module>
    with DAG(
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dag.py", line 650, in __init__
    raise ValueError("DAG is missing the start_date parameter")
ValueError: DAG is missing the start_date parameter
[2025-03-03T13:09:44.628-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:09:44.694-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.127 seconds
[2025-03-03T13:10:06.966-0600] {processor.py:186} INFO - Started process (PID=29706) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:10:06.968-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:10:06.974-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:10:06.972-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:10:06.991-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:10:06.986-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py", line 13, in <module>
    with DAG(
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dag.py", line 650, in __init__
    raise ValueError("DAG is missing the start_date parameter")
ValueError: DAG is missing the start_date parameter
[2025-03-03T13:10:06.993-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:10:07.053-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.105 seconds
[2025-03-03T13:10:24.277-0600] {processor.py:186} INFO - Started process (PID=29825) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:10:24.281-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:10:24.288-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:10:24.288-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:10:24.297-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:10:24.295-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 879, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1017, in get_code
  File "<frozen importlib._bootstrap_external>", line 947, in source_to_code
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py", line 17
    schedule = "@weekly"
             ^
SyntaxError: invalid syntax
[2025-03-03T13:10:24.299-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:10:24.370-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.108 seconds
[2025-03-03T13:10:43.465-0600] {processor.py:186} INFO - Started process (PID=29949) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:10:43.475-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:10:43.491-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:10:43.486-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:10:43.518-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:10:43.510-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 879, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1017, in get_code
  File "<frozen importlib._bootstrap_external>", line 947, in source_to_code
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py", line 16
    start_date = datetime(2025, 2, )
                 
SyntaxError: invalid syntax. Perhaps you forgot a comma?
[2025-03-03T13:10:43.520-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:10:43.793-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.383 seconds
[2025-03-03T13:10:52.847-0600] {processor.py:186} INFO - Started process (PID=30011) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:10:52.868-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:10:52.884-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:10:52.878-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:10:52.974-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:10:52.945-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 879, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1017, in get_code
  File "<frozen importlib._bootstrap_external>", line 947, in source_to_code
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py", line 16
    start_date = datetime(2025, 2, 19)
                 
SyntaxError: invalid syntax. Perhaps you forgot a comma?
[2025-03-03T13:10:52.993-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:10:53.423-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.616 seconds
[2025-03-03T13:11:34.185-0600] {processor.py:186} INFO - Started process (PID=30069) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:11:34.196-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:11:34.208-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:11:34.202-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:11:34.236-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:11:34.225-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 879, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1017, in get_code
  File "<frozen importlib._bootstrap_external>", line 947, in source_to_code
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py", line 16
    start_date = datetime(2025, 2, 19)
                 
SyntaxError: invalid syntax. Perhaps you forgot a comma?
[2025-03-03T13:11:34.237-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:11:34.362-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 3.102 seconds
[2025-03-03T13:11:56.068-0600] {processor.py:186} INFO - Started process (PID=30228) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:11:56.420-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:11:56.843-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:11:56.536-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:11:57.991-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:12:32.370-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:12:32.339-0600] {override.py:1930} INFO - Created Permission View: can edit on DAG:DataAnalysis
[2025-03-03T13:12:33.600-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:12:33.540-0600] {override.py:1930} INFO - Created Permission View: can read on DAG:DataAnalysis
[2025-03-03T13:12:34.291-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:12:34.268-0600] {override.py:1930} INFO - Created Permission View: can delete on DAG:DataAnalysis
[2025-03-03T13:12:35.416-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:12:35.339-0600] {override.py:1930} INFO - Created Permission View: menu access on DAG Run:DataAnalysis
[2025-03-03T13:12:36.203-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:12:36.171-0600] {override.py:1930} INFO - Created Permission View: can create on DAG Run:DataAnalysis
[2025-03-03T13:12:38.242-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:12:38.225-0600] {override.py:1930} INFO - Created Permission View: can read on DAG Run:DataAnalysis
[2025-03-03T13:12:38.318-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:12:38.316-0600] {override.py:1930} INFO - Created Permission View: can delete on DAG Run:DataAnalysis
[2025-03-03T13:12:38.320-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:12:38.319-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:12:38.363-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:12:38.362-0600] {dag.py:3262} INFO - Creating ORM DAG for DataAnalysis
[2025-03-03T13:12:38.391-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:12:38.390-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:12:38.475-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 42.678 seconds
[2025-03-03T13:13:45.226-0600] {processor.py:186} INFO - Started process (PID=30415) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:13:45.233-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:13:45.241-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:13:45.240-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:13:45.368-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:13:45.607-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:13:45.606-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:13:45.676-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:13:45.675-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:13:45.798-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 17.074 seconds
[2025-03-03T13:14:16.159-0600] {processor.py:186} INFO - Started process (PID=30701) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:14:16.162-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:14:16.166-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:14:16.166-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:14:16.189-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:14:16.277-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:14:16.277-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:14:16.338-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:14:16.337-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:14:16.402-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.259 seconds
[2025-03-03T13:14:46.846-0600] {processor.py:186} INFO - Started process (PID=30947) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:14:46.859-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:14:46.864-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:14:46.863-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:14:46.907-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:14:46.984-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:14:46.984-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:14:47.028-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:14:47.027-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:14:47.073-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.254 seconds
[2025-03-03T13:15:17.436-0600] {processor.py:186} INFO - Started process (PID=31214) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:15:17.440-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:15:17.456-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:15:17.454-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:15:17.546-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:15:17.712-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:15:17.711-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:15:17.787-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:15:17.786-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:15:17.844-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.428 seconds
[2025-03-03T13:15:48.174-0600] {processor.py:186} INFO - Started process (PID=31390) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:15:48.178-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:15:48.183-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:15:48.182-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:15:48.204-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:15:48.260-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:15:48.259-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:15:48.311-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:15:48.310-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:15:48.373-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.220 seconds
[2025-03-03T13:16:18.755-0600] {processor.py:186} INFO - Started process (PID=31536) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:16:18.758-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:16:18.764-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:16:18.763-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:16:18.800-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:16:18.885-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:16:18.884-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:16:18.954-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:16:18.954-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:16:19.005-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.266 seconds
[2025-03-03T13:16:49.356-0600] {processor.py:186} INFO - Started process (PID=31682) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:16:49.358-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:16:49.362-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:16:49.361-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:16:49.381-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:16:49.426-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:16:49.425-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:16:49.468-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:16:49.468-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:16:49.514-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.170 seconds
[2025-03-03T13:17:19.833-0600] {processor.py:186} INFO - Started process (PID=31837) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:17:19.838-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:17:19.841-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:17:19.841-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:17:19.861-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:17:19.910-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:17:19.910-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:17:19.959-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:17:19.958-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:17:20.008-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.185 seconds
[2025-03-03T13:17:50.330-0600] {processor.py:186} INFO - Started process (PID=31984) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:17:50.333-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:17:50.336-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:17:50.336-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:17:50.350-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:17:50.391-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:17:50.391-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:17:50.441-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:17:50.440-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:17:50.488-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.167 seconds
[2025-03-03T13:18:20.817-0600] {processor.py:186} INFO - Started process (PID=32131) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:18:20.819-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:18:20.823-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:18:20.822-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:18:20.841-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:18:20.887-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:18:20.886-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:18:20.936-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:18:20.936-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:18:20.990-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.185 seconds
[2025-03-03T13:18:51.336-0600] {processor.py:186} INFO - Started process (PID=32276) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:18:51.340-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:18:51.344-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:18:51.343-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:18:51.363-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:18:51.409-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:18:51.408-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:18:51.458-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:18:51.458-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:18:51.515-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.193 seconds
[2025-03-03T13:19:21.866-0600] {processor.py:186} INFO - Started process (PID=32422) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:19:21.868-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:19:21.871-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:19:21.870-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:19:21.887-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:19:21.928-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:19:21.927-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:19:21.976-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:19:21.976-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:19:22.023-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.168 seconds
[2025-03-03T13:19:52.358-0600] {processor.py:186} INFO - Started process (PID=32574) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:19:52.364-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:19:52.369-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:19:52.368-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:19:52.393-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:19:52.461-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:19:52.460-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:19:52.503-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:19:52.503-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:19:52.550-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.205 seconds
[2025-03-03T13:20:22.873-0600] {processor.py:186} INFO - Started process (PID=32719) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:20:22.877-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:20:22.881-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:20:22.880-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:20:22.898-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:20:22.944-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:20:22.943-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:20:22.983-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:20:22.983-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:20:23.028-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.166 seconds
[2025-03-03T13:20:53.387-0600] {processor.py:186} INFO - Started process (PID=32865) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:20:53.389-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:20:53.393-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:20:53.392-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:20:53.423-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:20:53.503-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:20:53.502-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:20:53.547-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:20:53.547-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:20:53.593-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.220 seconds
[2025-03-03T13:21:23.919-0600] {processor.py:186} INFO - Started process (PID=33013) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:21:23.922-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:21:23.925-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:21:23.924-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:21:23.940-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:21:23.982-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:21:23.981-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:21:24.020-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:21:24.020-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:21:24.075-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.165 seconds
[2025-03-03T13:21:54.426-0600] {processor.py:186} INFO - Started process (PID=33164) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:21:54.429-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:21:54.433-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:21:54.432-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:21:54.455-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:21:54.509-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:21:54.509-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:21:54.553-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:21:54.552-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:21:54.597-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.181 seconds
[2025-03-03T13:22:24.916-0600] {processor.py:186} INFO - Started process (PID=33310) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:22:24.919-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:22:24.922-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:22:24.921-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:22:24.940-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:22:24.983-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:22:24.983-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:22:25.026-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:22:25.026-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:22:25.069-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.163 seconds
[2025-03-03T13:22:55.413-0600] {processor.py:186} INFO - Started process (PID=33456) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:22:55.417-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:22:55.420-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:22:55.420-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:22:55.438-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:22:55.490-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:22:55.490-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:22:55.537-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:22:55.536-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:22:55.595-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.193 seconds
[2025-03-03T13:23:25.946-0600] {processor.py:186} INFO - Started process (PID=33601) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:23:25.948-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:23:25.953-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:23:25.953-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:23:25.973-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:23:26.026-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:23:26.026-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:23:26.061-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:23:26.060-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:23:26.098-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.168 seconds
[2025-03-03T13:23:56.437-0600] {processor.py:186} INFO - Started process (PID=33753) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:23:56.440-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:23:56.446-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:23:56.445-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:23:56.463-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:23:56.513-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:23:56.512-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:23:56.559-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:23:56.559-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:23:56.609-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.183 seconds
[2025-03-03T13:24:26.957-0600] {processor.py:186} INFO - Started process (PID=33898) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:24:26.960-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:24:26.967-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:24:26.966-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:24:26.986-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:24:27.038-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:24:27.037-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:24:27.086-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:24:27.086-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:24:27.140-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.195 seconds
[2025-03-03T13:24:57.488-0600] {processor.py:186} INFO - Started process (PID=34047) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:24:57.492-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:24:57.496-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:24:57.495-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:24:57.514-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:24:57.557-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:24:57.557-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:24:57.600-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:24:57.600-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:24:57.641-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.166 seconds
[2025-03-03T13:25:27.987-0600] {processor.py:186} INFO - Started process (PID=34193) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:25:27.991-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:25:27.995-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:25:27.994-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:25:28.013-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:25:28.062-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:25:28.062-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:25:28.108-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:25:28.107-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:25:28.160-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.184 seconds
[2025-03-03T13:25:58.521-0600] {processor.py:186} INFO - Started process (PID=34344) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:25:58.524-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:25:58.529-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:25:58.528-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:25:58.557-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:25:58.622-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:25:58.622-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:25:58.661-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:25:58.660-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:25:58.707-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.205 seconds
[2025-03-03T13:26:29.055-0600] {processor.py:186} INFO - Started process (PID=34492) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:26:29.060-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:26:29.064-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:26:29.063-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:26:29.084-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:26:29.147-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:26:29.146-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:26:29.188-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:26:29.187-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:26:29.246-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.204 seconds
[2025-03-03T13:26:59.603-0600] {processor.py:186} INFO - Started process (PID=34638) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:26:59.605-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:26:59.608-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:26:59.607-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:26:59.623-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:26:59.669-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:26:59.668-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:26:59.704-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:26:59.704-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:26:59.746-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.155 seconds
[2025-03-03T13:27:30.107-0600] {processor.py:186} INFO - Started process (PID=34789) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:27:30.111-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:27:30.114-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:27:30.113-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:27:30.132-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:27:30.187-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:27:30.187-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:27:30.226-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:27:30.226-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:27:30.275-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.179 seconds
[2025-03-03T13:28:00.623-0600] {processor.py:186} INFO - Started process (PID=34937) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:28:00.626-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:28:00.630-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:28:00.629-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:28:00.646-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:28:00.692-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:28:00.692-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:28:00.727-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:28:00.726-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:28:00.769-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.155 seconds
[2025-03-03T13:28:31.112-0600] {processor.py:186} INFO - Started process (PID=35082) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:28:31.114-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:28:31.118-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:28:31.118-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:28:31.139-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:28:31.193-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:28:31.191-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:28:31.237-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:28:31.236-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:28:31.284-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.184 seconds
[2025-03-03T13:29:01.628-0600] {processor.py:186} INFO - Started process (PID=35234) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:29:01.630-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:29:01.634-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:29:01.633-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:29:01.649-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:29:01.692-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:29:01.691-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:29:01.732-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:29:01.732-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:29:01.779-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.161 seconds
[2025-03-03T13:29:32.122-0600] {processor.py:186} INFO - Started process (PID=35380) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:29:32.125-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:29:32.129-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:29:32.128-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:29:32.148-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:29:32.191-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:29:32.190-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:29:32.233-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:29:32.232-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:29:32.272-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.162 seconds
[2025-03-03T13:30:02.614-0600] {processor.py:186} INFO - Started process (PID=35525) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:30:02.616-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:30:02.620-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:30:02.620-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:30:02.637-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:30:02.678-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:30:02.678-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:30:02.717-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:30:02.717-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:30:02.758-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.155 seconds
[2025-03-03T13:30:33.142-0600] {processor.py:186} INFO - Started process (PID=35673) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:30:33.146-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:30:33.151-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:30:33.150-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:30:33.177-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:30:33.246-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:30:33.246-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:30:33.306-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:30:33.305-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:30:33.371-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.249 seconds
[2025-03-03T13:31:03.731-0600] {processor.py:186} INFO - Started process (PID=35822) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:31:03.734-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:31:03.738-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:31:03.737-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:31:03.758-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:31:03.807-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:31:03.807-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:31:03.854-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:31:03.853-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:31:03.907-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.187 seconds
[2025-03-03T13:31:34.258-0600] {processor.py:186} INFO - Started process (PID=35970) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:31:34.262-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:31:34.266-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:31:34.265-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:31:34.285-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:31:34.336-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:31:34.335-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:31:34.397-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:31:34.396-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:31:34.451-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.206 seconds
[2025-03-03T13:32:04.811-0600] {processor.py:186} INFO - Started process (PID=36122) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:32:04.813-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:32:04.818-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:32:04.817-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:32:04.840-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:32:04.889-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:32:04.888-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:32:04.934-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:32:04.934-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:32:04.983-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.184 seconds
[2025-03-03T13:32:35.331-0600] {processor.py:186} INFO - Started process (PID=36267) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:32:35.335-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:32:35.339-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:32:35.338-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:32:35.359-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:32:35.406-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:32:35.406-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:32:35.457-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:32:35.456-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:32:35.529-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.210 seconds
[2025-03-03T13:33:05.900-0600] {processor.py:186} INFO - Started process (PID=36413) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:33:05.904-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:33:05.907-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:33:05.906-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:33:05.924-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:33:05.979-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:33:05.979-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:33:06.062-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:33:06.061-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:33:06.112-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.224 seconds
[2025-03-03T13:33:36.452-0600] {processor.py:186} INFO - Started process (PID=36565) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:33:36.454-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:33:36.459-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:33:36.458-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:33:36.478-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:33:36.524-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:33:36.524-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:33:36.578-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:33:36.577-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:33:36.623-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.184 seconds
[2025-03-03T13:34:06.965-0600] {processor.py:186} INFO - Started process (PID=36710) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:34:06.969-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:34:06.974-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:34:06.973-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:34:06.994-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:34:07.053-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:34:07.053-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:34:07.099-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:34:07.098-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:34:07.152-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.201 seconds
[2025-03-03T13:34:37.513-0600] {processor.py:186} INFO - Started process (PID=36856) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:34:37.516-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:34:37.520-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:34:37.519-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:34:37.537-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:34:37.583-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:34:37.582-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:34:37.628-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:34:37.627-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:34:37.678-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.176 seconds
[2025-03-03T13:35:08.047-0600] {processor.py:186} INFO - Started process (PID=37010) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:35:08.050-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:35:08.054-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:35:08.053-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:35:08.075-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:35:08.123-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:35:08.123-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:35:08.169-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:35:08.169-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:35:08.214-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.182 seconds
[2025-03-03T13:35:38.537-0600] {processor.py:186} INFO - Started process (PID=37156) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:35:38.539-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:35:38.542-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:35:38.541-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:35:38.559-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:35:38.599-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:35:38.598-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:35:38.635-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:35:38.635-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:35:38.689-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.162 seconds
[2025-03-03T13:36:09.031-0600] {processor.py:186} INFO - Started process (PID=37308) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:36:09.035-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:36:09.038-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:36:09.038-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:36:09.054-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:36:09.094-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:36:09.093-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:36:09.131-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:36:09.130-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:36:09.171-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.150 seconds
[2025-03-03T13:36:39.520-0600] {processor.py:186} INFO - Started process (PID=37453) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:36:39.523-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:36:39.526-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:36:39.526-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:36:39.543-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:36:39.587-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:36:39.586-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:36:39.638-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:36:39.638-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:36:39.692-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.183 seconds
[2025-03-03T13:37:10.047-0600] {processor.py:186} INFO - Started process (PID=37599) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:37:10.050-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:37:10.054-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:37:10.053-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:37:10.071-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:37:10.117-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:37:10.117-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:37:10.159-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:37:10.159-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:37:10.210-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.173 seconds
[2025-03-03T13:37:40.561-0600] {processor.py:186} INFO - Started process (PID=37750) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:37:40.563-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:37:40.567-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:37:40.567-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:37:40.586-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:37:40.642-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:37:40.641-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:37:40.692-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:37:40.691-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:37:40.743-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.204 seconds
[2025-03-03T13:38:11.108-0600] {processor.py:186} INFO - Started process (PID=37896) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:38:11.113-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:38:11.119-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:38:11.117-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:38:11.139-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:38:11.187-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:38:11.186-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:38:11.232-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:38:11.231-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:38:11.278-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.187 seconds
[2025-03-03T13:38:41.653-0600] {processor.py:186} INFO - Started process (PID=38049) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:38:41.654-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:38:41.657-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:38:41.657-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:38:41.671-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:38:41.710-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:38:41.710-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:38:41.747-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:38:41.747-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:38:41.789-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.144 seconds
[2025-03-03T13:39:12.116-0600] {processor.py:186} INFO - Started process (PID=38195) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:39:12.120-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:39:12.124-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:39:12.123-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:39:12.139-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:39:12.177-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:39:12.176-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:39:12.217-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:39:12.216-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:39:12.257-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.150 seconds
[2025-03-03T13:39:42.595-0600] {processor.py:186} INFO - Started process (PID=38340) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:39:42.598-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:39:42.601-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:39:42.600-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:39:42.617-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:39:42.664-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:39:42.663-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:39:42.702-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:39:42.701-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:39:42.744-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.160 seconds
[2025-03-03T13:40:13.092-0600] {processor.py:186} INFO - Started process (PID=38492) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:40:13.094-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:40:13.097-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:40:13.096-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:40:13.114-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:40:13.152-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:40:13.151-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:40:13.187-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:40:13.187-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:40:13.230-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.147 seconds
[2025-03-03T13:40:43.575-0600] {processor.py:186} INFO - Started process (PID=38637) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:40:43.578-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:40:43.582-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:40:43.581-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:40:43.598-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:40:43.650-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:40:43.650-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:40:43.705-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:40:43.704-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:40:43.757-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.194 seconds
[2025-03-03T13:41:14.123-0600] {processor.py:186} INFO - Started process (PID=38791) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:41:14.126-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:41:14.131-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:41:14.130-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:41:14.151-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:41:14.206-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:41:14.206-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:41:14.256-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:41:14.256-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:41:14.310-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.199 seconds
[2025-03-03T13:41:44.663-0600] {processor.py:186} INFO - Started process (PID=38937) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:41:44.665-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:41:44.669-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:41:44.669-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:41:44.691-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:41:44.742-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:41:44.741-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:41:44.798-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:41:44.797-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:41:44.873-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.222 seconds
[2025-03-03T13:42:15.231-0600] {processor.py:186} INFO - Started process (PID=39091) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:42:15.233-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:42:15.237-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:42:15.236-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:42:15.266-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:42:15.321-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:42:15.321-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:42:15.361-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:42:15.361-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:42:15.408-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.190 seconds
[2025-03-03T13:42:45.742-0600] {processor.py:186} INFO - Started process (PID=39236) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:42:45.746-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:42:45.750-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:42:45.749-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:42:45.771-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:42:45.823-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:42:45.822-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:42:45.866-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:42:45.865-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:42:45.921-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.189 seconds
[2025-03-03T13:43:16.273-0600] {processor.py:186} INFO - Started process (PID=39385) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:43:16.275-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:43:16.281-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:43:16.280-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:43:16.309-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:43:16.377-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:43:16.377-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:43:16.426-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:43:16.426-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:43:16.477-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.217 seconds
[2025-03-03T13:43:46.870-0600] {processor.py:186} INFO - Started process (PID=39534) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:43:46.872-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:43:46.881-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:43:46.879-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:43:46.900-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:43:46.956-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:43:46.956-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:43:46.996-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:43:46.996-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:43:47.049-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.196 seconds
[2025-03-03T13:44:17.402-0600] {processor.py:186} INFO - Started process (PID=39679) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:44:17.406-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:44:17.413-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:44:17.409-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:44:17.442-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:44:17.503-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:44:17.503-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:44:17.557-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:44:17.557-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:44:17.605-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.214 seconds
[2025-03-03T13:44:47.943-0600] {processor.py:186} INFO - Started process (PID=39832) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:44:47.945-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:44:47.949-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:44:47.948-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:44:47.968-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:44:48.017-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:44:48.016-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:44:48.065-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:44:48.064-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:44:48.116-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.183 seconds
[2025-03-03T13:45:18.470-0600] {processor.py:186} INFO - Started process (PID=39980) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:45:18.474-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:45:18.478-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:45:18.477-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:45:18.496-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:45:18.542-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:45:18.542-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:45:18.597-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:45:18.596-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:45:18.655-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.198 seconds
[2025-03-03T13:45:48.972-0600] {processor.py:186} INFO - Started process (PID=40132) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:45:48.975-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:45:48.979-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:45:48.978-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:45:48.996-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:45:49.042-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:45:49.042-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:45:49.091-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:45:49.091-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:45:49.150-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.188 seconds
[2025-03-03T13:46:19.474-0600] {processor.py:186} INFO - Started process (PID=40277) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:46:19.477-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:46:19.481-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:46:19.480-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:46:19.499-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:46:19.537-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:46:19.537-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:46:19.571-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:46:19.571-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:46:19.615-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.154 seconds
[2025-03-03T13:46:49.964-0600] {processor.py:186} INFO - Started process (PID=40429) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:46:49.967-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:46:49.970-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:46:49.970-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:46:49.987-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:46:50.034-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:46:50.033-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:46:50.071-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:46:50.071-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:46:50.122-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.169 seconds
[2025-03-03T13:47:20.471-0600] {processor.py:186} INFO - Started process (PID=40574) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:47:20.472-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:47:20.476-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:47:20.475-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:47:20.493-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:47:20.541-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:47:20.540-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:47:20.585-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:47:20.585-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:47:20.636-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.176 seconds
[2025-03-03T13:47:51.002-0600] {processor.py:186} INFO - Started process (PID=40726) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:47:51.005-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:47:51.009-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:47:51.008-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:47:51.027-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:47:51.079-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:47:51.078-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:47:51.116-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:47:51.115-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:47:51.159-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.168 seconds
[2025-03-03T13:48:21.482-0600] {processor.py:186} INFO - Started process (PID=40871) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:48:21.486-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:48:21.488-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:48:21.488-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:48:21.503-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:48:21.540-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:48:21.539-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:48:21.578-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:48:21.577-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:48:21.617-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.147 seconds
[2025-03-03T13:48:51.969-0600] {processor.py:186} INFO - Started process (PID=41025) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:48:51.971-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:48:51.976-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:48:51.975-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:48:51.992-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:48:52.036-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:48:52.035-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:48:52.089-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:48:52.089-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:48:52.145-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.187 seconds
[2025-03-03T13:49:22.505-0600] {processor.py:186} INFO - Started process (PID=41171) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:49:22.509-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:49:22.513-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:49:22.512-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:49:22.531-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:49:22.577-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:49:22.576-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:49:22.625-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:49:22.625-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:49:22.675-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.187 seconds
[2025-03-03T13:49:53.047-0600] {processor.py:186} INFO - Started process (PID=41322) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:49:53.049-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:49:53.054-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:49:53.053-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:49:53.076-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:49:53.135-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:49:53.134-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:49:53.180-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:49:53.180-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:49:53.235-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.203 seconds
[2025-03-03T13:50:23.607-0600] {processor.py:186} INFO - Started process (PID=41468) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:50:23.611-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:50:23.617-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:50:23.616-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:50:23.644-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:50:23.705-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:50:23.704-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:50:23.748-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:50:23.747-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:50:23.797-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.205 seconds
[2025-03-03T13:50:54.150-0600] {processor.py:186} INFO - Started process (PID=41619) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:50:54.152-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:50:54.156-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:50:54.155-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:50:54.174-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:50:54.223-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:50:54.223-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:50:54.271-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:50:54.271-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:50:54.318-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.181 seconds
[2025-03-03T13:51:24.670-0600] {processor.py:186} INFO - Started process (PID=41771) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:51:24.675-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:51:24.678-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:51:24.677-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:51:24.695-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:51:24.740-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:51:24.739-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:51:24.791-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:51:24.790-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:51:24.842-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.181 seconds
[2025-03-03T13:51:55.249-0600] {processor.py:186} INFO - Started process (PID=41919) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:51:55.257-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:51:55.262-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:51:55.261-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:51:55.287-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:51:55.360-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:51:55.360-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:51:55.394-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:51:55.394-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:51:55.444-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.252 seconds
[2025-03-03T13:52:25.804-0600] {processor.py:186} INFO - Started process (PID=42070) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:52:25.806-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:52:25.810-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:52:25.809-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:52:25.827-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:52:25.870-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:52:25.870-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:52:25.910-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:52:25.910-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:52:25.960-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.174 seconds
[2025-03-03T13:52:56.315-0600] {processor.py:186} INFO - Started process (PID=42216) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:52:56.317-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:52:56.321-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:52:56.320-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:52:56.340-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:52:56.384-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:52:56.383-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:52:56.426-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:52:56.425-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:52:56.478-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.174 seconds
[2025-03-03T13:53:26.831-0600] {processor.py:186} INFO - Started process (PID=42367) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:53:26.833-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:53:26.837-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:53:26.837-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:53:26.855-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:53:26.894-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:53:26.894-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:53:26.934-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:53:26.934-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:53:26.976-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.159 seconds
[2025-03-03T13:53:57.428-0600] {processor.py:186} INFO - Started process (PID=42676) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:53:57.438-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:53:57.442-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:53:57.442-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:53:57.486-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:53:57.538-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:53:57.538-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:53:57.622-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:53:57.622-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:53:57.686-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.346 seconds
[2025-03-03T13:54:28.022-0600] {processor.py:186} INFO - Started process (PID=42852) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:54:28.026-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:54:28.032-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:54:28.031-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:54:28.055-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:54:28.100-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:54:28.099-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:54:28.142-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:54:28.142-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:54:28.194-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.185 seconds
[2025-03-03T13:54:58.557-0600] {processor.py:186} INFO - Started process (PID=42999) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:54:58.559-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:54:58.562-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:54:58.562-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:54:58.582-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:54:58.624-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:54:58.623-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:54:58.667-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:54:58.667-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:54:58.713-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.167 seconds
[2025-03-03T13:55:29.108-0600] {processor.py:186} INFO - Started process (PID=43152) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:55:29.126-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:55:29.149-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:55:29.147-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:55:29.252-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:55:29.309-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:55:29.308-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:55:29.369-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:55:29.368-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:55:29.420-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.380 seconds
[2025-03-03T13:55:59.779-0600] {processor.py:186} INFO - Started process (PID=43299) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:55:59.780-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:55:59.784-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:55:59.783-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:55:59.803-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:55:59.871-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:55:59.871-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:55:59.913-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:55:59.912-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:55:59.962-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.194 seconds
[2025-03-03T13:56:30.334-0600] {processor.py:186} INFO - Started process (PID=43452) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:56:30.340-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:56:30.346-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:56:30.344-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:56:30.379-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:56:30.437-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:56:30.436-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:56:30.470-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:56:30.470-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:56:30.515-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.200 seconds
[2025-03-03T13:57:00.838-0600] {processor.py:186} INFO - Started process (PID=43712) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:57:00.841-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:57:00.847-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:57:00.846-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:57:00.867-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:57:00.911-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:57:00.910-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:57:00.976-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:57:00.975-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:57:01.046-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.220 seconds
[2025-03-03T13:57:31.399-0600] {processor.py:186} INFO - Started process (PID=43961) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:57:31.403-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:57:31.406-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:57:31.406-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:57:31.428-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:57:31.488-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:57:31.487-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:57:31.537-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:57:31.536-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:57:31.591-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.204 seconds
[2025-03-03T13:58:01.945-0600] {processor.py:186} INFO - Started process (PID=44184) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:58:01.947-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:58:01.951-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:58:01.950-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:58:01.969-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:58:02.017-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:58:02.016-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:58:02.060-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:58:02.060-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:58:02.108-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.176 seconds
[2025-03-03T13:58:32.454-0600] {processor.py:186} INFO - Started process (PID=44402) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:58:32.456-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:58:32.460-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:58:32.459-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:58:32.478-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:58:32.524-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:58:32.523-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:58:32.566-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:58:32.566-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:58:32.612-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.169 seconds
[2025-03-03T13:59:03.010-0600] {processor.py:186} INFO - Started process (PID=44699) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:59:03.013-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:59:03.018-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:59:03.017-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:59:03.042-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:59:03.105-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:59:03.104-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:59:03.153-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:59:03.152-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:59:03.229-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.234 seconds
[2025-03-03T13:59:33.581-0600] {processor.py:186} INFO - Started process (PID=44869) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:59:33.584-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T13:59:33.590-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:59:33.589-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:59:33.611-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T13:59:33.664-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:59:33.663-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T13:59:33.719-0600] {logging_mixin.py:190} INFO - [2025-03-03T13:59:33.718-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T13:59:33.785-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.218 seconds
[2025-03-03T14:00:04.158-0600] {processor.py:186} INFO - Started process (PID=45126) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T14:00:04.160-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py for tasks to queue
[2025-03-03T14:00:04.163-0600] {logging_mixin.py:190} INFO - [2025-03-03T14:00:04.163-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T14:00:04.180-0600] {processor.py:925} INFO - DAG(s) 'DataAnalysis' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py
[2025-03-03T14:00:04.223-0600] {logging_mixin.py:190} INFO - [2025-03-03T14:00:04.223-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-03T14:00:04.275-0600] {logging_mixin.py:190} INFO - [2025-03-03T14:00:04.275-0600] {dag.py:4180} INFO - Setting next_dagrun for DataAnalysis to 2025-02-23 00:00:00+00:00, run_after=2025-03-02 00:00:00+00:00
[2025-03-03T14:00:04.330-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dataAnalytics.py took 0.183 seconds
