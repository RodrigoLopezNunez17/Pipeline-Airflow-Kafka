[2025-02-19T13:52:34.472-0600] {processor.py:186} INFO - Started process (PID=476377) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T13:52:34.482-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T13:52:34.497-0600] {logging_mixin.py:190} INFO - [2025-02-19T13:52:34.494-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T13:52:34.587-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T13:52:34.673-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.273 seconds
[2025-02-19T13:53:04.960-0600] {processor.py:186} INFO - Started process (PID=476631) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T13:53:04.976-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T13:53:05.040-0600] {logging_mixin.py:190} INFO - [2025-02-19T13:53:05.034-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T13:53:05.205-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T13:53:05.344-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.466 seconds
[2025-02-19T13:53:18.253-0600] {processor.py:186} INFO - Started process (PID=476692) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T13:53:18.256-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T13:53:18.260-0600] {logging_mixin.py:190} INFO - [2025-02-19T13:53:18.259-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T13:53:18.268-0600] {logging_mixin.py:190} INFO - [2025-02-19T13:53:18.265-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 879, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1017, in get_code
  File "<frozen importlib._bootstrap_external>", line 947, in source_to_code
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py", line 20
    ) as dag:
             ^
IndentationError: expected an indented block after 'with' statement on line 16
[2025-02-19T13:53:18.269-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T13:53:18.350-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.107 seconds
[2025-02-19T13:53:23.347-0600] {processor.py:186} INFO - Started process (PID=476723) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T13:53:23.350-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T13:53:23.354-0600] {logging_mixin.py:190} INFO - [2025-02-19T13:53:23.353-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T13:53:23.360-0600] {logging_mixin.py:190} INFO - [2025-02-19T13:53:23.358-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 879, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1017, in get_code
  File "<frozen importlib._bootstrap_external>", line 947, in source_to_code
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py", line 21
    
    ^
IndentationError: expected an indented block after 'with' statement on line 16
[2025-02-19T13:53:23.360-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T13:53:23.415-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.080 seconds
[2025-02-19T13:53:25.042-0600] {processor.py:186} INFO - Started process (PID=476748) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T13:53:25.046-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T13:53:25.064-0600] {logging_mixin.py:190} INFO - [2025-02-19T13:53:25.057-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T13:53:25.122-0600] {logging_mixin.py:190} INFO - [2025-02-19T13:53:25.112-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 879, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1017, in get_code
  File "<frozen importlib._bootstrap_external>", line 947, in source_to_code
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py", line 21
    
    ^
IndentationError: expected an indented block after 'with' statement on line 16
[2025-02-19T13:53:25.123-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T13:53:25.213-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.235 seconds
[2025-02-19T13:53:31.337-0600] {processor.py:186} INFO - Started process (PID=476779) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T13:53:31.345-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T13:53:31.372-0600] {logging_mixin.py:190} INFO - [2025-02-19T13:53:31.370-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T13:53:31.435-0600] {logging_mixin.py:190} INFO - [2025-02-19T13:53:31.433-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py", line 19, in <module>
    schedule_interval=deltatime(minutes=1),
NameError: name 'deltatime' is not defined
[2025-02-19T13:53:31.436-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T13:53:31.570-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.297 seconds
[2025-02-19T13:53:31.589-0600] {processor.py:186} INFO - Started process (PID=476780) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T13:53:31.591-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T13:53:31.594-0600] {logging_mixin.py:190} INFO - [2025-02-19T13:53:31.593-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T13:53:31.638-0600] {logging_mixin.py:190} INFO - [2025-02-19T13:53:31.636-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py", line 19, in <module>
    schedule_interval=deltatime(minutes=1),
NameError: name 'deltatime' is not defined
[2025-02-19T13:53:31.639-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T13:53:31.671-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.143 seconds
[2025-02-19T13:53:42.893-0600] {processor.py:186} INFO - Started process (PID=476895) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T13:53:42.895-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T13:53:42.904-0600] {logging_mixin.py:190} INFO - [2025-02-19T13:53:42.902-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T13:53:42.924-0600] {logging_mixin.py:190} INFO - [2025-02-19T13:53:42.923-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py", line 19, in <module>
    schedule_interval=deltatime(minutes=1),
NameError: name 'deltatime' is not defined
[2025-02-19T13:53:42.925-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T13:53:42.962-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.080 seconds
[2025-02-19T13:53:43.024-0600] {processor.py:186} INFO - Started process (PID=476896) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T13:53:43.029-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T13:53:43.034-0600] {logging_mixin.py:190} INFO - [2025-02-19T13:53:43.033-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T13:53:43.060-0600] {logging_mixin.py:190} INFO - [2025-02-19T13:53:43.057-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py", line 19, in <module>
    schedule_interval=deltatime(minutes=1),
NameError: name 'deltatime' is not defined
[2025-02-19T13:53:43.062-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T13:53:43.112-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.103 seconds
[2025-02-19T13:54:10.534-0600] {processor.py:186} INFO - Started process (PID=477106) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T13:54:10.537-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T13:54:10.561-0600] {logging_mixin.py:190} INFO - [2025-02-19T13:54:10.558-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T13:54:10.621-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T13:54:10.625-0600] {processor.py:186} INFO - Started process (PID=477107) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T13:54:10.626-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T13:54:10.636-0600] {logging_mixin.py:190} INFO - [2025-02-19T13:54:10.633-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T13:54:10.643-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T13:54:10.740-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T13:54:10.745-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T13:54:11.135-0600] {logging_mixin.py:190} INFO - [2025-02-19T13:54:11.134-0600] {override.py:1930} INFO - Created Permission View: can edit on DAG:DAG_1
[2025-02-19T13:54:11.162-0600] {logging_mixin.py:190} INFO - [2025-02-19T13:54:11.161-0600] {override.py:1930} INFO - Created Permission View: can delete on DAG:DAG_1
[2025-02-19T13:54:11.192-0600] {logging_mixin.py:190} INFO - [2025-02-19T13:54:11.190-0600] {override.py:1930} INFO - Created Permission View: can read on DAG:DAG_1
[2025-02-19T13:54:11.238-0600] {logging_mixin.py:190} INFO - [2025-02-19T13:54:11.237-0600] {override.py:1930} INFO - Created Permission View: can delete on DAG Run:DAG_1
[2025-02-19T13:54:11.262-0600] {logging_mixin.py:190} INFO - [2025-02-19T13:54:11.261-0600] {override.py:1930} INFO - Created Permission View: menu access on DAG Run:DAG_1
[2025-02-19T13:54:11.291-0600] {logging_mixin.py:190} INFO - [2025-02-19T13:54:11.290-0600] {override.py:1930} INFO - Created Permission View: can read on DAG Run:DAG_1
[2025-02-19T13:54:11.312-0600] {logging_mixin.py:190} INFO - [2025-02-19T13:54:11.311-0600] {override.py:1930} INFO - Created Permission View: can create on DAG Run:DAG_1
[2025-02-19T13:54:11.313-0600] {logging_mixin.py:190} INFO - [2025-02-19T13:54:11.313-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T13:54:11.340-0600] {logging_mixin.py:190} INFO - [2025-02-19T13:54:11.339-0600] {dag.py:3262} INFO - Creating ORM DAG for DAG_1
[2025-02-19T13:54:11.384-0600] {logging_mixin.py:190} INFO - [2025-02-19T13:54:11.383-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 00:00:00+00:00, run_after=2025-02-19 00:01:00+00:00
[2025-02-19T13:54:11.448-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.963 seconds
[2025-02-19T13:54:11.531-0600] {logging_mixin.py:190} INFO - [2025-02-19T13:54:11.530-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T13:54:11.631-0600] {logging_mixin.py:190} INFO - [2025-02-19T13:54:11.630-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 00:00:00+00:00, run_after=2025-02-19 00:01:00+00:00
[2025-02-19T13:54:11.805-0600] {logging_mixin.py:190} INFO - [2025-02-19T13:54:11.797-0600] {dagbag.py:698} ERROR - Failed to write serialized DAG: /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 686, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/serialized_dag.py", line 160, in write_dag
    if session.scalar(
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('DAG_1', '/home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py', 12174270372636950, '{"__version": 1, "dag": {"start_date": 1739923200.0, "fileloc": "/home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py", "_task_group": {"_group_ ... (1105 characters truncated) ... ask", "_is_empty": false, "start_trigger_args": null, "op_args": [], "op_kwargs": {}}, "__type": "operator"}], "dag_dependencies": [], "params": []}}', None, '2025-02-19 19:54:10.823080', '51d87d64188f2e976a8a67b95a6dd94e', '/home/dataScience/Projects/Pipeline/airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-02-19T13:54:11.806-0600] {logging_mixin.py:190} INFO - [2025-02-19T13:54:11.806-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T13:54:11.808-0600] {processor.py:211} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 207, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 188, in _handle_dag_file_processing
    result: tuple[int, int, int] = dag_file_processor.process_file(
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 942, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/api_internal/internal_api_call.py", line 166, in wrapper
    return func(*args, **kwargs)
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/dag_processing/processor.py", line 982, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 708, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/tenacity/__init__.py", line 443, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/tenacity/__init__.py", line 376, in iter
    result = action(retry_state)
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/usr/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 724, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dag.py", line 3252, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (sqlite3.IntegrityError) UNIQUE constraint failed: serialized_dag.dag_id
[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (?, ?, ?, ?, ?, ?, ?, ?)]
[parameters: ('DAG_1', '/home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py', 12174270372636950, '{"__version": 1, "dag": {"start_date": 1739923200.0, "fileloc": "/home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py", "_task_group": {"_group_ ... (1105 characters truncated) ... ask", "_is_empty": false, "start_trigger_args": null, "op_args": [], "op_kwargs": {}}, "__type": "operator"}], "dag_dependencies": [], "params": []}}', None, '2025-02-19 19:54:10.823080', '51d87d64188f2e976a8a67b95a6dd94e', '/home/dataScience/Projects/Pipeline/airflow/dags')]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-02-19T13:54:41.753-0600] {processor.py:186} INFO - Started process (PID=477624) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T13:54:41.757-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T13:54:41.776-0600] {logging_mixin.py:190} INFO - [2025-02-19T13:54:41.771-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T13:54:41.858-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T13:54:41.869-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T13:54:41.939-0600] {logging_mixin.py:190} INFO - [2025-02-19T13:54:41.939-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T13:54:42.017-0600] {logging_mixin.py:190} INFO - [2025-02-19T13:54:42.016-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 00:00:00+00:00, run_after=2025-02-19 00:01:00+00:00
[2025-02-19T13:54:42.088-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.373 seconds
[2025-02-19T13:54:42.883-0600] {processor.py:186} INFO - Started process (PID=477636) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T13:54:42.885-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T13:54:42.888-0600] {logging_mixin.py:190} INFO - [2025-02-19T13:54:42.887-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T13:54:42.922-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T13:54:42.924-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T13:54:42.985-0600] {logging_mixin.py:190} INFO - [2025-02-19T13:54:42.984-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T13:54:43.043-0600] {logging_mixin.py:190} INFO - [2025-02-19T13:54:43.043-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 00:00:00+00:00, run_after=2025-02-19 00:01:00+00:00
[2025-02-19T13:54:43.133-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.263 seconds
[2025-02-19T13:55:13.043-0600] {processor.py:186} INFO - Started process (PID=478347) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T13:55:13.047-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T13:55:13.058-0600] {logging_mixin.py:190} INFO - [2025-02-19T13:55:13.057-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T13:55:13.094-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T13:55:13.103-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T13:55:13.156-0600] {logging_mixin.py:190} INFO - [2025-02-19T13:55:13.155-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T13:55:13.203-0600] {logging_mixin.py:190} INFO - [2025-02-19T13:55:13.202-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 00:00:00+00:00, run_after=2025-02-19 00:01:00+00:00
[2025-02-19T13:55:13.250-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.245 seconds
[2025-02-19T13:55:13.794-0600] {processor.py:186} INFO - Started process (PID=478348) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T13:55:13.795-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T13:55:13.797-0600] {logging_mixin.py:190} INFO - [2025-02-19T13:55:13.796-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T13:55:13.816-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T13:55:13.817-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T13:55:13.858-0600] {logging_mixin.py:190} INFO - [2025-02-19T13:55:13.858-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T13:55:13.889-0600] {logging_mixin.py:190} INFO - [2025-02-19T13:55:13.888-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 00:00:00+00:00, run_after=2025-02-19 00:01:00+00:00
[2025-02-19T13:55:13.935-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.153 seconds
[2025-02-19T13:55:43.907-0600] {processor.py:186} INFO - Started process (PID=478770) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T13:55:43.909-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T13:55:43.915-0600] {logging_mixin.py:190} INFO - [2025-02-19T13:55:43.914-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T13:55:43.938-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T13:55:43.943-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T13:55:43.982-0600] {logging_mixin.py:190} INFO - [2025-02-19T13:55:43.981-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T13:55:44.031-0600] {logging_mixin.py:190} INFO - [2025-02-19T13:55:44.031-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 00:00:00+00:00, run_after=2025-02-19 00:01:00+00:00
[2025-02-19T13:55:44.075-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.180 seconds
[2025-02-19T13:55:44.410-0600] {processor.py:186} INFO - Started process (PID=478782) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T13:55:44.412-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T13:55:44.415-0600] {logging_mixin.py:190} INFO - [2025-02-19T13:55:44.414-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T13:55:44.432-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T13:55:44.434-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T13:55:44.483-0600] {logging_mixin.py:190} INFO - [2025-02-19T13:55:44.483-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T13:55:44.514-0600] {logging_mixin.py:190} INFO - [2025-02-19T13:55:44.514-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 00:00:00+00:00, run_after=2025-02-19 00:01:00+00:00
[2025-02-19T13:55:44.551-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.152 seconds
[2025-02-19T13:56:14.223-0600] {processor.py:186} INFO - Started process (PID=479657) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T13:56:14.234-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T13:56:14.262-0600] {logging_mixin.py:190} INFO - [2025-02-19T13:56:14.259-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T13:56:14.408-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T13:56:14.441-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T13:56:14.648-0600] {logging_mixin.py:190} INFO - [2025-02-19T13:56:14.647-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T13:56:14.748-0600] {logging_mixin.py:190} INFO - [2025-02-19T13:56:14.748-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 00:00:00+00:00, run_after=2025-02-19 00:01:00+00:00
[2025-02-19T13:56:14.807-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.634 seconds
[2025-02-19T13:56:15.116-0600] {processor.py:186} INFO - Started process (PID=479665) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T13:56:15.118-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T13:56:15.122-0600] {logging_mixin.py:190} INFO - [2025-02-19T13:56:15.121-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T13:56:15.153-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T13:56:15.155-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T13:56:15.210-0600] {logging_mixin.py:190} INFO - [2025-02-19T13:56:15.210-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T13:56:15.250-0600] {logging_mixin.py:190} INFO - [2025-02-19T13:56:15.249-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 00:00:00+00:00, run_after=2025-02-19 00:01:00+00:00
[2025-02-19T13:56:15.315-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.243 seconds
[2025-02-19T13:56:45.812-0600] {processor.py:186} INFO - Started process (PID=480115) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T13:56:45.818-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T13:56:45.839-0600] {logging_mixin.py:190} INFO - [2025-02-19T13:56:45.830-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T13:56:45.847-0600] {processor.py:186} INFO - Started process (PID=480116) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T13:56:45.850-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T13:56:45.863-0600] {logging_mixin.py:190} INFO - [2025-02-19T13:56:45.861-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T13:56:45.944-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T13:56:45.955-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T13:56:45.959-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T13:56:45.971-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T13:56:46.575-0600] {logging_mixin.py:190} INFO - [2025-02-19T13:56:46.382-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T13:56:46.575-0600] {logging_mixin.py:190} INFO - [2025-02-19T13:56:46.381-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T13:57:31.619-0600] {logging_mixin.py:190} INFO - [2025-02-19T13:57:28.676-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 00:00:00+00:00, run_after=2025-02-19 00:01:00+00:00
[2025-02-19T13:57:42.890-0600] {logging_mixin.py:190} INFO - [2025-02-19T13:57:38.332-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 00:00:00+00:00, run_after=2025-02-19 00:01:00+00:00
[2025-02-19T13:57:53.059-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 67.309 seconds
[2025-02-19T13:57:53.180-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 67.363 seconds
[2025-02-19T13:59:10.798-0600] {processor.py:186} INFO - Started process (PID=480457) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T13:59:10.939-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T13:59:11.637-0600] {logging_mixin.py:190} INFO - [2025-02-19T13:59:11.345-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T13:59:15.023-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T13:59:17.369-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T13:59:23.797-0600] {processor.py:186} INFO - Started process (PID=480496) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T13:59:23.931-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T13:59:24.154-0600] {logging_mixin.py:190} INFO - [2025-02-19T13:59:24.064-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T13:59:25.030-0600] {logging_mixin.py:190} INFO - [2025-02-19T13:59:25.029-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T13:59:25.299-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T13:59:25.322-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T13:59:25.360-0600] {logging_mixin.py:190} INFO - [2025-02-19T13:59:25.359-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 00:00:00+00:00, run_after=2025-02-19 00:01:00+00:00
[2025-02-19T13:59:25.574-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 15.126 seconds
[2025-02-19T13:59:25.916-0600] {logging_mixin.py:190} INFO - [2025-02-19T13:59:25.915-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T13:59:26.363-0600] {logging_mixin.py:190} INFO - [2025-02-19T13:59:26.361-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 00:00:00+00:00, run_after=2025-02-19 00:01:00+00:00
[2025-02-19T13:59:26.540-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 9.744 seconds
[2025-02-19T13:59:56.381-0600] {processor.py:186} INFO - Started process (PID=481590) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T13:59:56.400-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T13:59:56.451-0600] {logging_mixin.py:190} INFO - [2025-02-19T13:59:56.445-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T13:59:57.383-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T13:59:57.457-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T13:59:58.040-0600] {processor.py:186} INFO - Started process (PID=481597) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T13:59:58.116-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T13:59:58.275-0600] {logging_mixin.py:190} INFO - [2025-02-19T13:59:58.231-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T13:59:58.389-0600] {logging_mixin.py:190} INFO - [2025-02-19T13:59:58.388-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T13:59:58.583-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T13:59:58.596-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T13:59:58.626-0600] {logging_mixin.py:190} INFO - [2025-02-19T13:59:58.624-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 00:00:00+00:00, run_after=2025-02-19 00:01:00+00:00
[2025-02-19T13:59:58.780-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 2.576 seconds
[2025-02-19T13:59:58.943-0600] {logging_mixin.py:190} INFO - [2025-02-19T13:59:58.943-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T13:59:59.186-0600] {logging_mixin.py:190} INFO - [2025-02-19T13:59:59.183-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 00:00:00+00:00, run_after=2025-02-19 00:01:00+00:00
[2025-02-19T13:59:59.400-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 2.032 seconds
[2025-02-19T14:00:29.802-0600] {processor.py:186} INFO - Started process (PID=482201) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:00:29.874-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:00:30.065-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:00:29.929-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:00:36.449-0600] {processor.py:186} INFO - Started process (PID=482204) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:00:36.456-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:00:36.925-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:00:39.439-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:00:38.834-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:00:40.797-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:00:56.491-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:00:56.500-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:00:56.523-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:00:56.521-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:00:56.657-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:00:56.656-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 00:00:00+00:00, run_after=2025-02-19 00:01:00+00:00
[2025-02-19T14:00:56.707-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:00:56.706-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:00:56.747-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 27.268 seconds
[2025-02-19T14:00:56.941-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:00:56.939-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 00:00:00+00:00, run_after=2025-02-19 00:01:00+00:00
[2025-02-19T14:00:57.033-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 23.478 seconds
[2025-02-19T14:01:27.079-0600] {processor.py:186} INFO - Started process (PID=482530) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:01:27.082-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:01:27.089-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:01:27.087-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:01:27.130-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:01:27.144-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:01:27.217-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:01:27.216-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:01:27.284-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:01:27.283-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 00:00:00+00:00, run_after=2025-02-19 00:01:00+00:00
[2025-02-19T14:01:27.334-0600] {processor.py:186} INFO - Started process (PID=482542) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:01:27.336-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:01:27.341-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:01:27.340-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:01:27.343-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.286 seconds
[2025-02-19T14:01:27.370-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:01:27.372-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:01:27.419-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:01:27.419-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:01:27.456-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:01:27.456-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 00:00:00+00:00, run_after=2025-02-19 00:01:00+00:00
[2025-02-19T14:01:27.498-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.189 seconds
[2025-02-19T14:01:57.569-0600] {processor.py:186} INFO - Started process (PID=483461) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:01:57.573-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:01:57.578-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:01:57.577-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:01:57.602-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:01:57.607-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:01:57.650-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:01:57.650-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:01:57.696-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:01:57.695-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 00:00:00+00:00, run_after=2025-02-19 00:01:00+00:00
[2025-02-19T14:01:57.736-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.182 seconds
[2025-02-19T14:01:57.786-0600] {processor.py:186} INFO - Started process (PID=483462) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:01:57.789-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:01:57.791-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:01:57.790-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:01:57.806-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:01:57.807-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:01:57.842-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:01:57.841-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:01:57.872-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:01:57.872-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 00:00:00+00:00, run_after=2025-02-19 00:01:00+00:00
[2025-02-19T14:01:57.912-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.144 seconds
[2025-02-19T14:02:27.900-0600] {processor.py:186} INFO - Started process (PID=483554) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:02:27.904-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:02:27.907-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:02:27.906-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:02:27.924-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:02:27.928-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:02:27.975-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:02:27.974-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:02:28.032-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:02:28.032-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 00:00:00+00:00, run_after=2025-02-19 00:01:00+00:00
[2025-02-19T14:02:28.088-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.201 seconds
[2025-02-19T14:02:28.116-0600] {processor.py:186} INFO - Started process (PID=483555) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:02:28.117-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:02:28.120-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:02:28.119-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:02:28.139-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:02:28.140-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:02:28.216-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:02:28.208-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:02:28.257-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:02:28.256-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 00:00:00+00:00, run_after=2025-02-19 00:01:00+00:00
[2025-02-19T14:02:28.306-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.202 seconds
[2025-02-19T14:02:58.282-0600] {processor.py:186} INFO - Started process (PID=483736) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:02:58.286-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:02:58.290-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:02:58.289-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:02:58.310-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:02:58.315-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:02:58.422-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:02:58.421-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:02:58.515-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:02:58.515-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 00:00:00+00:00, run_after=2025-02-19 00:01:00+00:00
[2025-02-19T14:02:58.575-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.305 seconds
[2025-02-19T14:02:58.581-0600] {processor.py:186} INFO - Started process (PID=483737) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:02:58.583-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:02:58.586-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:02:58.585-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:02:58.603-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:02:58.604-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:02:58.640-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:02:58.639-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:02:58.677-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:02:58.677-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 00:00:00+00:00, run_after=2025-02-19 00:01:00+00:00
[2025-02-19T14:02:58.733-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.192 seconds
[2025-02-19T14:03:28.850-0600] {processor.py:186} INFO - Started process (PID=483834) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:03:28.855-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:03:28.859-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:03:28.858-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:03:28.886-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:03:28.896-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:03:28.899-0600] {processor.py:186} INFO - Started process (PID=483836) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:03:28.902-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:03:28.906-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:03:28.905-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:03:28.975-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:03:28.977-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:03:28.999-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:03:28.998-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:03:29.068-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:03:29.067-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 00:00:00+00:00, run_after=2025-02-19 00:01:00+00:00
[2025-02-19T14:03:29.078-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:03:29.077-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:03:29.133-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.296 seconds
[2025-02-19T14:03:29.152-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:03:29.151-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 00:00:00+00:00, run_after=2025-02-19 00:01:00+00:00
[2025-02-19T14:03:29.200-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.321 seconds
[2025-02-19T14:03:59.326-0600] {processor.py:186} INFO - Started process (PID=484048) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:03:59.330-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:03:59.335-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:03:59.334-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:03:59.358-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:03:59.363-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:03:59.392-0600] {processor.py:186} INFO - Started process (PID=484049) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:03:59.394-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:03:59.397-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:03:59.397-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:03:59.414-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:03:59.413-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:03:59.425-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:03:59.427-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:03:59.460-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:03:59.459-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 00:00:00+00:00, run_after=2025-02-19 00:01:00+00:00
[2025-02-19T14:03:59.467-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:03:59.466-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:03:59.504-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:03:59.504-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 00:00:00+00:00, run_after=2025-02-19 00:01:00+00:00
[2025-02-19T14:03:59.509-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.194 seconds
[2025-02-19T14:03:59.547-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.172 seconds
[2025-02-19T14:04:29.661-0600] {processor.py:186} INFO - Started process (PID=484158) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:04:29.666-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:04:29.669-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:04:29.669-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:04:29.690-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:04:29.696-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:04:29.740-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:04:29.739-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:04:29.746-0600] {processor.py:186} INFO - Started process (PID=484159) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:04:29.749-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:04:29.752-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:04:29.751-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:04:29.776-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:04:29.778-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:04:29.783-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:04:29.782-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 00:00:00+00:00, run_after=2025-02-19 00:01:00+00:00
[2025-02-19T14:04:29.823-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:04:29.823-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:04:29.828-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.179 seconds
[2025-02-19T14:04:29.861-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:04:29.861-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 00:00:00+00:00, run_after=2025-02-19 00:01:00+00:00
[2025-02-19T14:04:29.907-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.175 seconds
[2025-02-19T14:04:59.971-0600] {processor.py:186} INFO - Started process (PID=484728) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:04:59.974-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:04:59.977-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:04:59.977-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:05:00.010-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:05:00.026-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:05:00.097-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:05:00.096-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:05:00.104-0600] {processor.py:186} INFO - Started process (PID=484729) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:05:00.107-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:05:00.109-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:05:00.109-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:05:00.130-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:05:00.131-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:05:00.140-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:05:00.140-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 00:00:00+00:00, run_after=2025-02-19 00:01:00+00:00
[2025-02-19T14:05:00.187-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:05:00.186-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:05:00.192-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.231 seconds
[2025-02-19T14:05:00.222-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:05:00.221-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 00:00:00+00:00, run_after=2025-02-19 00:01:00+00:00
[2025-02-19T14:05:00.256-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.165 seconds
[2025-02-19T14:05:30.912-0600] {processor.py:186} INFO - Started process (PID=485211) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:05:30.913-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:05:30.916-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:05:30.916-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:05:30.934-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:05:30.937-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:05:30.970-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:05:30.969-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:05:31.006-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:05:31.005-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 00:04:00+00:00, run_after=2025-02-19 00:05:00+00:00
[2025-02-19T14:05:31.045-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.144 seconds
[2025-02-19T14:06:02.840-0600] {processor.py:186} INFO - Started process (PID=485884) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:06:02.843-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:06:02.847-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:06:02.847-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:06:02.861-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:06:02.865-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:06:02.896-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:06:02.896-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:06:02.937-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:06:02.936-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 00:12:00+00:00, run_after=2025-02-19 00:13:00+00:00
[2025-02-19T14:06:02.975-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.145 seconds
[2025-02-19T14:06:36.729-0600] {processor.py:186} INFO - Started process (PID=486576) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:06:36.731-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:06:36.738-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:06:36.735-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:06:36.756-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:06:36.762-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:06:36.795-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:06:36.795-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:06:36.829-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:06:36.828-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 00:21:00+00:00, run_after=2025-02-19 00:22:00+00:00
[2025-02-19T14:06:36.867-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.147 seconds
[2025-02-19T14:07:09.421-0600] {processor.py:186} INFO - Started process (PID=487294) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:07:09.422-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:07:09.425-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:07:09.425-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:07:09.440-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:07:09.446-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:07:09.487-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:07:09.486-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:07:09.521-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:07:09.520-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 00:29:00+00:00, run_after=2025-02-19 00:30:00+00:00
[2025-02-19T14:07:09.558-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.148 seconds
[2025-02-19T14:07:40.673-0600] {processor.py:186} INFO - Started process (PID=487909) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:07:40.678-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:07:40.684-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:07:40.683-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:07:40.702-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:07:40.707-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:07:40.745-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:07:40.745-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:07:40.794-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:07:40.793-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 00:36:00+00:00, run_after=2025-02-19 00:37:00+00:00
[2025-02-19T14:07:40.853-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.192 seconds
[2025-02-19T14:08:11.214-0600] {processor.py:186} INFO - Started process (PID=488325) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:08:11.217-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:08:11.225-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:08:11.224-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:08:11.291-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:08:11.303-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:08:11.414-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:08:11.413-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:08:11.459-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:08:11.459-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 00:36:00+00:00, run_after=2025-02-19 00:37:00+00:00
[2025-02-19T14:08:11.505-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.347 seconds
[2025-02-19T14:08:41.672-0600] {processor.py:186} INFO - Started process (PID=488479) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:08:41.676-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:08:41.683-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:08:41.682-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:08:41.704-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:08:41.709-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:08:41.748-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:08:41.747-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:08:41.787-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:08:41.787-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 00:36:00+00:00, run_after=2025-02-19 00:37:00+00:00
[2025-02-19T14:08:41.830-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.171 seconds
[2025-02-19T14:09:12.190-0600] {processor.py:186} INFO - Started process (PID=488594) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:09:12.194-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:09:12.198-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:09:12.197-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:09:12.215-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:09:12.221-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:09:12.260-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:09:12.258-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:09:12.307-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:09:12.303-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 00:36:00+00:00, run_after=2025-02-19 00:37:00+00:00
[2025-02-19T14:09:12.519-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.340 seconds
[2025-02-19T14:09:42.708-0600] {processor.py:186} INFO - Started process (PID=489034) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:09:42.712-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:09:42.718-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:09:42.717-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:09:42.738-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:09:42.743-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:09:42.785-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:09:42.784-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:09:42.824-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:09:42.823-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 00:36:00+00:00, run_after=2025-02-19 00:37:00+00:00
[2025-02-19T14:09:42.866-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.169 seconds
[2025-02-19T14:10:13.133-0600] {processor.py:186} INFO - Started process (PID=489167) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:10:13.136-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:10:13.140-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:10:13.139-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:10:13.162-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:10:13.167-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:10:13.209-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:10:13.209-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:10:13.256-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:10:13.255-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 00:36:00+00:00, run_after=2025-02-19 00:37:00+00:00
[2025-02-19T14:10:13.305-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.185 seconds
[2025-02-19T14:10:43.737-0600] {processor.py:186} INFO - Started process (PID=489168) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:10:43.742-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:10:43.746-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:10:43.745-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:10:43.766-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:10:43.770-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:10:43.806-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:10:43.805-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:10:43.843-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:10:43.842-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 00:36:00+00:00, run_after=2025-02-19 00:37:00+00:00
[2025-02-19T14:10:43.891-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.167 seconds
[2025-02-19T14:11:14.478-0600] {processor.py:186} INFO - Started process (PID=489225) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:11:14.480-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:11:14.483-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:11:14.482-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:11:14.498-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:11:14.502-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:11:14.534-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:11:14.534-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:11:14.567-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:11:14.567-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 00:36:00+00:00, run_after=2025-02-19 00:37:00+00:00
[2025-02-19T14:11:14.604-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.138 seconds
[2025-02-19T14:11:44.756-0600] {processor.py:186} INFO - Started process (PID=489226) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:11:44.760-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:11:44.764-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:11:44.763-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:11:44.778-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:11:44.782-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:11:44.811-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:11:44.811-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:11:44.840-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:11:44.840-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 00:36:00+00:00, run_after=2025-02-19 00:37:00+00:00
[2025-02-19T14:11:44.874-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.127 seconds
[2025-02-19T14:12:15.182-0600] {processor.py:186} INFO - Started process (PID=489304) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:12:15.187-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:12:15.192-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:12:15.191-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:12:15.210-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:12:15.215-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:12:15.250-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:12:15.250-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:12:15.294-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:12:15.294-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 00:36:00+00:00, run_after=2025-02-19 00:37:00+00:00
[2025-02-19T14:12:15.332-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.163 seconds
[2025-02-19T14:12:45.516-0600] {processor.py:186} INFO - Started process (PID=489305) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:12:45.519-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:12:45.525-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:12:45.524-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:12:45.545-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:12:45.549-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:12:45.587-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:12:45.587-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:12:45.624-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:12:45.624-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 00:36:00+00:00, run_after=2025-02-19 00:37:00+00:00
[2025-02-19T14:12:45.667-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.165 seconds
[2025-02-19T14:13:15.842-0600] {processor.py:186} INFO - Started process (PID=489414) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:13:15.848-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:13:15.853-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:13:15.852-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:13:15.873-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:13:15.877-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:13:15.912-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:13:15.911-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:13:15.949-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:13:15.949-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 00:36:00+00:00, run_after=2025-02-19 00:37:00+00:00
[2025-02-19T14:13:15.992-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.161 seconds
[2025-02-19T14:13:46.184-0600] {processor.py:186} INFO - Started process (PID=489415) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:13:46.187-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:13:46.193-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:13:46.193-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:13:46.210-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:13:46.217-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:13:46.255-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:13:46.255-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:13:46.292-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:13:46.291-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 00:36:00+00:00, run_after=2025-02-19 00:37:00+00:00
[2025-02-19T14:13:46.333-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.160 seconds
[2025-02-19T14:14:16.546-0600] {processor.py:186} INFO - Started process (PID=489471) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:14:16.548-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:14:16.552-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:14:16.551-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:14:16.584-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:14:16.590-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:14:16.655-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:14:16.653-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:14:16.733-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:14:16.732-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 00:36:00+00:00, run_after=2025-02-19 00:37:00+00:00
[2025-02-19T14:14:16.790-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.260 seconds
[2025-02-19T14:14:47.005-0600] {processor.py:186} INFO - Started process (PID=489584) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:14:47.008-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:14:47.015-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:14:47.014-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:14:47.039-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:14:47.045-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:14:47.101-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:14:47.101-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:14:47.159-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:14:47.158-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 00:36:00+00:00, run_after=2025-02-19 00:37:00+00:00
[2025-02-19T14:14:47.228-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.238 seconds
[2025-02-19T14:15:17.444-0600] {processor.py:186} INFO - Started process (PID=489639) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:15:17.445-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:15:17.452-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:15:17.450-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:15:17.471-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:15:17.476-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:15:17.508-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:15:17.507-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:15:17.543-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:15:17.543-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 00:36:00+00:00, run_after=2025-02-19 00:37:00+00:00
[2025-02-19T14:15:17.581-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.153 seconds
[2025-02-19T14:15:47.771-0600] {processor.py:186} INFO - Started process (PID=489750) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:15:47.778-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:15:47.798-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:15:47.794-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:15:47.854-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:15:47.866-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:15:47.968-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:15:47.967-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:15:48.039-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:15:48.038-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 00:36:00+00:00, run_after=2025-02-19 00:37:00+00:00
[2025-02-19T14:15:48.085-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.333 seconds
[2025-02-19T14:16:14.786-0600] {processor.py:186} INFO - Started process (PID=489859) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:16:14.788-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:16:14.791-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:16:14.791-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:16:14.814-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:16:14.819-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:16:15.369-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:16:15.368-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:16:15.429-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:16:15.428-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 00:36:00+00:00, run_after=2025-02-19 00:41:00+00:00
[2025-02-19T14:16:15.502-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.728 seconds
[2025-02-19T14:16:39.525-0600] {processor.py:186} INFO - Started process (PID=489970) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:16:39.529-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:16:39.534-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:16:39.533-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:16:39.555-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:16:39.559-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:16:39.574-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:16:39.573-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:16:39.698-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:16:39.697-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 00:36:00+00:00, run_after=2025-02-19 00:41:00+00:00
[2025-02-19T14:16:39.812-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.299 seconds
[2025-02-19T14:16:52.069-0600] {processor.py:186} INFO - Started process (PID=489973) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:16:52.071-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:16:52.075-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:16:52.074-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:16:52.086-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:16:52.079-0600] {dagbag.py:387} ERROR - Failed to import: /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
Traceback (most recent call last):
  File "/home/dataScience/Projects/Pipeline/venv/lib/python3.10/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 879, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1017, in get_code
  File "<frozen importlib._bootstrap_external>", line 947, in source_to_code
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py", line 12
    p.produce(topic = "quickstart-events", value = f"The current time is : {}")
                                                                              ^
SyntaxError: f-string: empty expression not allowed
[2025-02-19T14:16:52.087-0600] {processor.py:927} WARNING - No viable dags retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:16:52.129-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.073 seconds
[2025-02-19T14:17:04.584-0600] {processor.py:186} INFO - Started process (PID=490031) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:17:04.585-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:17:04.591-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:17:04.590-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:17:04.610-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:17:04.615-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:17:04.648-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:17:04.647-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:17:04.689-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:17:04.688-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 00:36:00+00:00, run_after=2025-02-19 00:41:00+00:00
[2025-02-19T14:17:04.743-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.169 seconds
[2025-02-19T14:17:35.894-0600] {processor.py:186} INFO - Started process (PID=490198) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:17:35.904-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:17:35.924-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:17:35.922-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:17:36.019-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:17:36.035-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:17:36.204-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:17:36.203-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:17:36.313-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:17:36.312-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 00:36:00+00:00, run_after=2025-02-19 00:41:00+00:00
[2025-02-19T14:17:36.378-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.621 seconds
[2025-02-19T14:18:07.295-0600] {processor.py:186} INFO - Started process (PID=490667) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:18:07.297-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:18:07.300-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:18:07.299-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:18:07.316-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:18:07.320-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:18:07.354-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:18:07.353-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:18:07.387-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:18:07.387-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 01:06:00+00:00, run_after=2025-02-19 01:11:00+00:00
[2025-02-19T14:18:07.424-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.139 seconds
[2025-02-19T14:18:25.973-0600] {processor.py:186} INFO - Started process (PID=491010) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:18:25.975-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:18:25.979-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:18:25.978-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:18:25.994-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:18:25.997-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:18:26.030-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:18:26.029-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:18:26.060-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:18:26.060-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 01:31:00+00:00, run_after=2025-02-19 01:36:00+00:00
[2025-02-19T14:18:26.102-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.138 seconds
[2025-02-19T14:18:56.652-0600] {processor.py:186} INFO - Started process (PID=491538) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:18:56.653-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:18:56.657-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:18:56.656-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:18:56.674-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:18:56.680-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:18:56.712-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:18:56.711-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:18:56.740-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:18:56.739-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 02:11:00+00:00, run_after=2025-02-19 02:16:00+00:00
[2025-02-19T14:18:56.775-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.132 seconds
[2025-02-19T14:19:28.030-0600] {processor.py:186} INFO - Started process (PID=492099) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:19:28.033-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:19:28.037-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:19:28.036-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:19:28.052-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:19:28.056-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:19:28.087-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:19:28.086-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:19:28.115-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:19:28.115-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 02:51:00+00:00, run_after=2025-02-19 02:56:00+00:00
[2025-02-19T14:19:28.160-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.139 seconds
[2025-02-19T14:19:59.746-0600] {processor.py:186} INFO - Started process (PID=492667) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:19:59.748-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:19:59.751-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:19:59.750-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:19:59.768-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:19:59.773-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:19:59.816-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:19:59.815-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:19:59.851-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:19:59.851-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 03:31:00+00:00, run_after=2025-02-19 03:36:00+00:00
[2025-02-19T14:19:59.892-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.158 seconds
[2025-02-19T14:20:32.003-0600] {processor.py:186} INFO - Started process (PID=493235) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:20:32.006-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:20:32.009-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:20:32.009-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:20:32.026-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:20:32.031-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:20:32.061-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:20:32.060-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:20:32.090-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:20:32.089-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 04:11:00+00:00, run_after=2025-02-19 04:16:00+00:00
[2025-02-19T14:20:32.128-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.133 seconds
[2025-02-19T14:21:03.906-0600] {processor.py:186} INFO - Started process (PID=493806) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:21:03.907-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:21:03.910-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:21:03.909-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:21:03.933-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:21:03.939-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:21:03.976-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:21:03.976-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:21:04.009-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:21:04.008-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 04:51:00+00:00, run_after=2025-02-19 04:56:00+00:00
[2025-02-19T14:21:04.046-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.149 seconds
[2025-02-19T14:21:07.419-0600] {processor.py:186} INFO - Started process (PID=493847) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:21:07.422-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:21:07.425-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:21:07.425-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:21:07.441-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:21:07.445-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:21:07.653-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:21:07.652-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:21:07.684-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:21:07.684-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 04:56:00+00:00, run_after=2025-02-19 04:56:30+00:00
[2025-02-19T14:21:07.727-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.317 seconds
[2025-02-19T14:21:39.816-0600] {processor.py:186} INFO - Started process (PID=494424) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:21:39.817-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:21:39.821-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:21:39.820-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:21:39.836-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:21:39.840-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:21:39.871-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:21:39.870-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:21:39.909-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:21:39.909-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 05:00:00+00:00, run_after=2025-02-19 05:00:30+00:00
[2025-02-19T14:21:39.950-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.144 seconds
[2025-02-19T14:22:13.898-0600] {processor.py:186} INFO - Started process (PID=495025) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:22:13.900-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:22:13.904-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:22:13.903-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:22:13.920-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:22:13.925-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:22:13.959-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:22:13.958-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:22:13.993-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:22:13.993-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 05:04:00+00:00, run_after=2025-02-19 05:04:30+00:00
[2025-02-19T14:22:14.032-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.144 seconds
[2025-02-19T14:22:46.807-0600] {processor.py:186} INFO - Started process (PID=495586) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:22:46.808-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:22:46.813-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:22:46.812-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:22:46.832-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:22:46.837-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:22:46.870-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:22:46.869-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:22:46.906-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:22:46.906-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 05:08:00+00:00, run_after=2025-02-19 05:08:30+00:00
[2025-02-19T14:22:46.949-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.152 seconds
[2025-02-19T14:23:17.346-0600] {processor.py:186} INFO - Started process (PID=496110) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:23:17.348-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:23:17.352-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:23:17.351-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:23:17.371-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:23:17.375-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:23:17.406-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:23:17.406-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:23:17.439-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:23:17.438-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 05:11:30+00:00, run_after=2025-02-19 05:12:00+00:00
[2025-02-19T14:23:17.474-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.139 seconds
[2025-02-19T14:23:48.390-0600] {processor.py:186} INFO - Started process (PID=496561) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:23:48.394-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:23:48.398-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:23:48.396-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:23:48.415-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:23:48.419-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:23:48.462-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:23:48.462-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:23:48.502-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:23:48.502-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 05:13:30+00:00, run_after=2025-02-19 05:14:00+00:00
[2025-02-19T14:23:48.544-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.165 seconds
[2025-02-19T14:24:18.738-0600] {processor.py:186} INFO - Started process (PID=496716) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:24:18.742-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:24:18.745-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:24:18.745-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:24:18.775-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:24:18.784-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:24:18.840-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:24:18.840-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:24:18.908-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:24:18.908-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 05:13:30+00:00, run_after=2025-02-19 05:14:00+00:00
[2025-02-19T14:24:18.971-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.248 seconds
[2025-02-19T14:24:49.194-0600] {processor.py:186} INFO - Started process (PID=496771) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:24:49.197-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:24:49.201-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:24:49.200-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:24:49.220-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:24:49.225-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:24:49.264-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:24:49.264-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:24:49.300-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:24:49.300-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 05:13:30+00:00, run_after=2025-02-19 05:14:00+00:00
[2025-02-19T14:24:49.342-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.160 seconds
[2025-02-19T14:25:19.537-0600] {processor.py:186} INFO - Started process (PID=496826) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:25:19.541-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:25:19.545-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:25:19.544-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:25:19.568-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:25:19.573-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:25:19.614-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:25:19.613-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:25:19.652-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:25:19.651-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 05:13:30+00:00, run_after=2025-02-19 05:14:00+00:00
[2025-02-19T14:25:19.699-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.175 seconds
[2025-02-19T14:25:49.857-0600] {processor.py:186} INFO - Started process (PID=496827) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:25:49.860-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:25:49.864-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:25:49.863-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:25:49.882-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:25:49.887-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:25:49.918-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:25:49.917-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:25:49.950-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:25:49.949-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 05:13:30+00:00, run_after=2025-02-19 05:14:00+00:00
[2025-02-19T14:25:49.990-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.142 seconds
[2025-02-19T14:26:20.179-0600] {processor.py:186} INFO - Started process (PID=496884) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:26:20.182-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:26:20.185-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:26:20.184-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:26:20.202-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:26:20.207-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:26:20.237-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:26:20.237-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:26:20.276-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:26:20.275-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 05:13:30+00:00, run_after=2025-02-19 05:14:00+00:00
[2025-02-19T14:26:20.317-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.148 seconds
[2025-02-19T14:26:50.446-0600] {processor.py:186} INFO - Started process (PID=496885) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:26:50.449-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:26:50.456-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:26:50.454-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:26:50.477-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:26:50.484-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:26:50.526-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:26:50.525-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:26:50.567-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:26:50.566-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 05:13:30+00:00, run_after=2025-02-19 05:14:00+00:00
[2025-02-19T14:26:50.608-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.174 seconds
[2025-02-19T14:27:20.755-0600] {processor.py:186} INFO - Started process (PID=496940) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:27:20.759-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:27:20.763-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:27:20.762-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:27:20.780-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:27:20.785-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:27:20.825-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:27:20.824-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:27:20.869-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:27:20.869-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 05:13:30+00:00, run_after=2025-02-19 05:14:00+00:00
[2025-02-19T14:27:20.910-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.170 seconds
[2025-02-19T14:27:51.088-0600] {processor.py:186} INFO - Started process (PID=496943) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:27:51.089-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:27:51.094-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:27:51.093-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:27:51.111-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:27:51.116-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:27:51.152-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:27:51.152-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:27:51.185-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:27:51.185-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 05:13:30+00:00, run_after=2025-02-19 05:14:00+00:00
[2025-02-19T14:27:51.228-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.150 seconds
[2025-02-19T14:28:21.415-0600] {processor.py:186} INFO - Started process (PID=497052) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:28:21.419-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:28:21.423-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:28:21.422-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:28:21.442-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:28:21.447-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:28:21.500-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:28:21.499-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:28:21.620-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:28:21.619-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 05:13:30+00:00, run_after=2025-02-19 05:14:00+00:00
[2025-02-19T14:28:21.745-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.343 seconds
[2025-02-19T14:28:51.982-0600] {processor.py:186} INFO - Started process (PID=497053) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:28:51.985-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:28:51.992-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:28:51.991-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:28:52.014-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:28:52.019-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:28:52.075-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:28:52.074-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:28:52.116-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:28:52.116-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 05:13:30+00:00, run_after=2025-02-19 05:14:00+00:00
[2025-02-19T14:28:52.164-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.198 seconds
[2025-02-19T14:29:22.442-0600] {processor.py:186} INFO - Started process (PID=497108) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:29:22.446-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:29:22.450-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:29:22.449-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:29:22.471-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:29:22.476-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:29:22.514-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:29:22.514-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:29:22.553-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:29:22.553-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 05:13:30+00:00, run_after=2025-02-19 05:14:00+00:00
[2025-02-19T14:29:22.598-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.170 seconds
[2025-02-19T14:29:52.764-0600] {processor.py:186} INFO - Started process (PID=497109) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:29:52.766-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:29:52.773-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:29:52.772-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:29:52.795-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:29:52.800-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:29:52.835-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:29:52.835-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:29:52.869-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:29:52.868-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 05:13:30+00:00, run_after=2025-02-19 05:14:00+00:00
[2025-02-19T14:29:52.915-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.165 seconds
[2025-02-19T14:30:23.102-0600] {processor.py:186} INFO - Started process (PID=497164) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:30:23.105-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:30:23.110-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:30:23.109-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:30:23.154-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:30:23.162-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:30:23.324-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:30:23.323-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:30:23.394-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:30:23.394-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 05:13:30+00:00, run_after=2025-02-19 05:14:00+00:00
[2025-02-19T14:30:23.441-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.355 seconds
[2025-02-19T14:30:53.668-0600] {processor.py:186} INFO - Started process (PID=497249) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:30:53.672-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:30:53.676-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:30:53.675-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:30:53.696-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:30:53.701-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:30:53.743-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:30:53.742-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:30:53.783-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:30:53.783-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 05:13:30+00:00, run_after=2025-02-19 05:14:00+00:00
[2025-02-19T14:30:53.834-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.179 seconds
[2025-02-19T14:31:24.011-0600] {processor.py:186} INFO - Started process (PID=497336) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:31:24.013-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:31:24.016-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:31:24.016-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:31:24.034-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:31:24.038-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:31:24.072-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:31:24.071-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:31:24.106-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:31:24.106-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 05:13:30+00:00, run_after=2025-02-19 05:14:00+00:00
[2025-02-19T14:31:24.154-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.155 seconds
[2025-02-19T14:31:54.364-0600] {processor.py:186} INFO - Started process (PID=497337) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:31:54.367-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:31:54.374-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:31:54.373-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:31:54.396-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:31:54.401-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:31:54.445-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:31:54.444-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:31:54.483-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:31:54.482-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 05:13:30+00:00, run_after=2025-02-19 05:14:00+00:00
[2025-02-19T14:31:54.530-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.184 seconds
[2025-02-19T14:32:24.714-0600] {processor.py:186} INFO - Started process (PID=497394) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:32:24.718-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:32:24.723-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:32:24.722-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:32:24.742-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:32:24.748-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:32:24.785-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:32:24.784-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:32:24.818-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:32:24.817-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 05:13:30+00:00, run_after=2025-02-19 05:14:00+00:00
[2025-02-19T14:32:24.862-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.160 seconds
[2025-02-19T14:32:55.082-0600] {processor.py:186} INFO - Started process (PID=497395) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:32:55.085-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:32:55.089-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:32:55.088-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:32:55.107-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:32:55.113-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:32:55.149-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:32:55.148-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:32:55.186-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:32:55.186-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 05:13:30+00:00, run_after=2025-02-19 05:14:00+00:00
[2025-02-19T14:32:55.230-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.161 seconds
[2025-02-19T14:33:25.384-0600] {processor.py:186} INFO - Started process (PID=497504) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:33:25.386-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:33:25.389-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:33:25.389-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:33:25.404-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:33:25.408-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:33:25.438-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:33:25.437-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:33:25.493-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:33:25.492-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 05:13:30+00:00, run_after=2025-02-19 05:14:00+00:00
[2025-02-19T14:33:25.587-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.213 seconds
[2025-02-19T14:33:55.819-0600] {processor.py:186} INFO - Started process (PID=497505) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:33:55.822-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:33:55.826-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:33:55.825-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:33:55.845-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:33:55.851-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:33:55.886-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:33:55.885-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:33:55.923-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:33:55.922-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 05:13:30+00:00, run_after=2025-02-19 05:14:00+00:00
[2025-02-19T14:33:55.980-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.174 seconds
[2025-02-19T14:34:26.162-0600] {processor.py:186} INFO - Started process (PID=497560) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:34:26.165-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:34:26.171-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:34:26.169-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:34:26.197-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:34:26.203-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:34:26.241-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:34:26.240-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:34:26.280-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:34:26.280-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 05:13:30+00:00, run_after=2025-02-19 05:14:00+00:00
[2025-02-19T14:34:26.322-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.172 seconds
[2025-02-19T14:34:56.526-0600] {processor.py:186} INFO - Started process (PID=497589) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:34:56.531-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:34:56.535-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:34:56.534-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:34:56.555-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:34:56.561-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:34:56.598-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:34:56.597-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:34:56.644-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:34:56.644-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 05:13:30+00:00, run_after=2025-02-19 05:14:00+00:00
[2025-02-19T14:34:56.692-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.181 seconds
[2025-02-19T14:35:26.875-0600] {processor.py:186} INFO - Started process (PID=497701) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:35:26.879-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:35:26.884-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:35:26.883-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:35:26.910-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:35:26.916-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:35:26.961-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:35:26.961-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:35:27.006-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:35:27.006-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 05:13:30+00:00, run_after=2025-02-19 05:14:00+00:00
[2025-02-19T14:35:27.059-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.198 seconds
[2025-02-19T14:35:57.341-0600] {processor.py:186} INFO - Started process (PID=497703) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:35:57.343-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:35:57.347-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:35:57.346-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:35:57.367-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:35:57.372-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:35:57.415-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:35:57.414-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:35:57.484-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:35:57.484-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 05:13:30+00:00, run_after=2025-02-19 05:14:00+00:00
[2025-02-19T14:35:57.563-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.235 seconds
[2025-02-19T14:36:27.795-0600] {processor.py:186} INFO - Started process (PID=497774) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:36:27.797-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:36:27.801-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:36:27.801-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:36:27.823-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:36:27.828-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:36:27.902-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:36:27.901-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:36:28.006-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:36:28.005-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 05:13:30+00:00, run_after=2025-02-19 05:14:00+00:00
[2025-02-19T14:36:28.077-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.297 seconds
[2025-02-19T14:36:58.397-0600] {processor.py:186} INFO - Started process (PID=497783) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:36:58.400-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:36:58.410-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:36:58.409-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:36:58.442-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:36:58.448-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:36:58.518-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:36:58.518-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:36:58.649-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:36:58.648-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 05:13:30+00:00, run_after=2025-02-19 05:14:00+00:00
[2025-02-19T14:36:58.731-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.352 seconds
[2025-02-19T14:37:28.937-0600] {processor.py:186} INFO - Started process (PID=497838) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:37:28.942-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:37:28.950-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:37:28.948-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:37:28.979-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:37:28.991-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:37:29.088-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:37:29.087-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:37:29.143-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:37:29.142-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 05:13:30+00:00, run_after=2025-02-19 05:14:00+00:00
[2025-02-19T14:37:29.199-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.280 seconds
[2025-02-19T14:37:59.412-0600] {processor.py:186} INFO - Started process (PID=497839) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:37:59.417-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:37:59.424-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:37:59.423-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:37:59.449-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:37:59.461-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:37:59.524-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:37:59.523-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:37:59.571-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:37:59.570-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 05:13:30+00:00, run_after=2025-02-19 05:14:00+00:00
[2025-02-19T14:37:59.655-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.267 seconds
[2025-02-19T14:38:29.825-0600] {processor.py:186} INFO - Started process (PID=497948) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:38:29.828-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:38:29.833-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:38:29.831-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:38:29.851-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:38:29.854-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:38:29.885-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:38:29.884-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:38:29.919-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:38:29.918-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 05:13:30+00:00, run_after=2025-02-19 05:14:00+00:00
[2025-02-19T14:38:29.982-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.167 seconds
[2025-02-19T14:39:00.157-0600] {processor.py:186} INFO - Started process (PID=497972) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:39:00.158-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:39:00.161-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:39:00.161-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:39:00.176-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:39:00.180-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:39:00.207-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:39:00.207-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:39:00.238-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:39:00.237-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 05:13:30+00:00, run_after=2025-02-19 05:14:00+00:00
[2025-02-19T14:39:00.272-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.125 seconds
[2025-02-19T14:39:30.495-0600] {processor.py:186} INFO - Started process (PID=498004) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:39:30.499-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:39:30.506-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:39:30.504-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:39:30.525-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:39:30.532-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:39:30.579-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:39:30.578-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:39:30.632-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:39:30.631-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 05:13:30+00:00, run_after=2025-02-19 05:14:00+00:00
[2025-02-19T14:39:30.677-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.197 seconds
[2025-02-19T14:40:00.936-0600] {processor.py:186} INFO - Started process (PID=498028) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:40:00.939-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:40:00.944-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:40:00.943-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:40:00.966-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:40:00.979-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:40:01.064-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:40:01.062-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:40:01.113-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:40:01.113-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 05:13:30+00:00, run_after=2025-02-19 05:14:00+00:00
[2025-02-19T14:40:01.153-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.229 seconds
[2025-02-19T14:40:31.375-0600] {processor.py:186} INFO - Started process (PID=498060) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:40:31.379-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:40:31.386-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:40:31.385-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:40:31.413-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:40:31.418-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:40:31.466-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:40:31.465-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:40:31.507-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:40:31.506-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 05:13:30+00:00, run_after=2025-02-19 05:14:00+00:00
[2025-02-19T14:40:31.560-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.199 seconds
[2025-02-19T14:41:01.788-0600] {processor.py:186} INFO - Started process (PID=498117) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:41:01.791-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:41:01.795-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:41:01.794-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:41:01.816-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:41:01.820-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:41:01.861-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:41:01.860-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:41:01.972-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:41:01.972-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 05:13:30+00:00, run_after=2025-02-19 05:14:00+00:00
[2025-02-19T14:41:02.069-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.298 seconds
[2025-02-19T14:41:32.251-0600] {processor.py:186} INFO - Started process (PID=498120) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:41:32.254-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:41:32.260-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:41:32.259-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:41:32.283-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:41:32.289-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:41:32.332-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:41:32.331-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:41:32.372-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:41:32.372-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 05:13:30+00:00, run_after=2025-02-19 05:14:00+00:00
[2025-02-19T14:41:32.412-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.175 seconds
[2025-02-19T14:42:02.616-0600] {processor.py:186} INFO - Started process (PID=498175) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:42:02.618-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:42:02.621-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:42:02.620-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:42:02.638-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:42:02.642-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:42:02.678-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:42:02.678-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:42:02.718-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:42:02.718-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 05:13:30+00:00, run_after=2025-02-19 05:14:00+00:00
[2025-02-19T14:42:02.761-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.175 seconds
[2025-02-19T14:42:32.947-0600] {processor.py:186} INFO - Started process (PID=498176) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:42:32.951-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:42:32.961-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:42:32.960-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:42:32.984-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:42:32.989-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:42:33.029-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:42:33.028-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:42:33.068-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:42:33.067-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 05:13:30+00:00, run_after=2025-02-19 05:14:00+00:00
[2025-02-19T14:42:33.112-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.182 seconds
[2025-02-19T14:43:03.292-0600] {processor.py:186} INFO - Started process (PID=498231) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:43:03.293-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:43:03.299-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:43:03.298-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:43:03.315-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:43:03.319-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:43:03.355-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:43:03.354-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:43:03.390-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:43:03.390-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 05:13:30+00:00, run_after=2025-02-19 05:14:00+00:00
[2025-02-19T14:43:03.429-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.148 seconds
[2025-02-19T14:43:33.626-0600] {processor.py:186} INFO - Started process (PID=498286) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:43:33.630-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:43:33.635-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:43:33.634-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:43:33.654-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:43:33.658-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:43:33.695-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:43:33.694-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:43:33.748-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:43:33.747-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 05:13:30+00:00, run_after=2025-02-19 05:14:00+00:00
[2025-02-19T14:43:33.842-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.230 seconds
[2025-02-19T14:44:04.110-0600] {processor.py:186} INFO - Started process (PID=498341) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:44:04.118-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:44:04.135-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:44:04.133-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:44:04.211-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:44:04.223-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:44:04.335-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:44:04.335-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:44:04.385-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:44:04.384-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 05:13:30+00:00, run_after=2025-02-19 05:14:00+00:00
[2025-02-19T14:44:04.435-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.375 seconds
[2025-02-19T14:44:34.720-0600] {processor.py:186} INFO - Started process (PID=498406) to work on /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:44:34.738-0600] {processor.py:914} INFO - Processing file /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py for tasks to queue
[2025-02-19T14:44:34.763-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:44:34.760-0600] {dagbag.py:588} INFO - Filling up the DagBag from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:44:34.846-0600] {logging_mixin.py:190} INFO - DAG_1 is ready!
[2025-02-19T14:44:34.870-0600] {processor.py:925} INFO - DAG(s) 'DAG_1' retrieved from /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py
[2025-02-19T14:44:34.988-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:44:34.988-0600] {dag.py:3239} INFO - Sync 1 DAGs
[2025-02-19T14:44:35.104-0600] {logging_mixin.py:190} INFO - [2025-02-19T14:44:35.103-0600] {dag.py:4180} INFO - Setting next_dagrun for DAG_1 to 2025-02-19 05:13:30+00:00, run_after=2025-02-19 05:14:00+00:00
[2025-02-19T14:44:35.205-0600] {processor.py:208} INFO - Processing /home/dataScience/Projects/Pipeline/airflow/dags/dag_1.py took 0.567 seconds
